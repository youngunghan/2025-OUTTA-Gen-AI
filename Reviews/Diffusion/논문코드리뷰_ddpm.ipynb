{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Paper : \"Denoising Diffusion Probabilistic Models\" by Jonathan Ho et al. (2020)\n",
        "# The code below was written with reference to the paper's official open source code.\n",
        "# Github Repository : https://github.com/hojonathanho/diffusion"
      ],
      "metadata": {
        "id": "dtK6Fk4zwOe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DqCxK8V1wJcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Model"
      ],
      "metadata": {
        "id": "Qwh2QMRkpNri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swish(x):\n",
        "    # Activation function used in DDPM\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "def get_timestep_embedding(t, channel):\n",
        "    \"\"\"\n",
        "    DDPM recieves timestep t as input to estimate the noise value.\n",
        "    This embedding fuction takes timestep t as input and returns embedding vector according to t.\n",
        "\n",
        "    Parameters:\n",
        "        t (torch.Tensor) : Timesteps of batch data\n",
        "        channel (int) : Number of embedding channels\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : Embedding vector\n",
        "    \"\"\"\n",
        "    half = channel // 2\n",
        "    device = t.device\n",
        "    freqs = torch.exp(\n",
        "        -torch.arange(half, dtype=torch.float32, device=device) * 2.0 * 3.1415 / float(half)\n",
        "    )\n",
        "    embedded = []\n",
        "    for val in t.float():\n",
        "        sin_embed = torch.sin(val * freqs)\n",
        "        cos_embed = torch.cos(val * freqs)\n",
        "        embedded.append(torch.cat([sin_embed, cos_embed], dim=0))\n",
        "    embedded = torch.stack(embedded, dim=0)\n",
        "    if channel % 2 == 1:\n",
        "        embedded = F.pad(embedded, (0,1,0,0))\n",
        "    return embedded  # (B, channel)\n",
        "\n",
        "class GroupNorm32(nn.GroupNorm):\n",
        "    def __init__(self, num_channels, num_groups=32, eps=1e-6):\n",
        "        super().__init__(num_groups, num_channels, eps=eps)\n",
        "\n",
        "def conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True, init_scale=1.0):\n",
        "    conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=bias)\n",
        "    with torch.no_grad():\n",
        "        conv.weight.data *= init_scale\n",
        "    return conv\n",
        "\n",
        "def nin(in_ch, out_ch, init_scale=1.0):\n",
        "    # 1x1 convolution\n",
        "    layer = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)\n",
        "    with torch.no_grad():\n",
        "        layer.weight.data *= init_scale\n",
        "    return layer\n",
        "\n",
        "def linear(in_features, out_features, init_scale=1.0):\n",
        "    fc = nn.Linear(in_features, out_features)\n",
        "    with torch.no_grad():\n",
        "        fc.weight.data *= init_scale\n",
        "    return fc\n",
        "\n",
        "class DownsampleBlock(nn.Module):\n",
        "    # Block that doubles down on resolution. Use convolution block or average pooling block.\n",
        "    def __init__(self, channels, with_conv=True):\n",
        "        super().__init__()\n",
        "        if with_conv:\n",
        "            self.op = nn.Conv2d(channels, channels, kernel_size=3, stride=2, padding=1)\n",
        "        else:\n",
        "            self.op = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.op(x)\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    # Block that doubles the resolution. Use interpolating block.\n",
        "    def __init__(self, channels, with_conv=True):\n",
        "        super().__init__()\n",
        "        self.with_conv = with_conv\n",
        "        if with_conv:\n",
        "            self.conv = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
        "        if self.with_conv:\n",
        "            x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Resnet block used in DDPM. Use group normalization. Timestep t is also received as input.\n",
        "\n",
        "    Parameters:\n",
        "        in_channels (int) : Number of input channels\n",
        "        out_channels (int) : Number of Output channels\n",
        "        temb_channels (int) : Number of time embedding channels\n",
        "        dropout (float) : Dropout rate\n",
        "        conv_shortcut (bool) : Whether to add convolution shortcut\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels=None,\n",
        "                 temb_channels=512, dropout=0.0, conv_shortcut=False):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels if out_channels is not None else in_channels\n",
        "        self.temb_channels = temb_channels\n",
        "        self.dropout = dropout\n",
        "        self.conv_shortcut = conv_shortcut\n",
        "\n",
        "        self.norm1 = GroupNorm32(self.in_channels)\n",
        "        self.conv1 = conv2d(self.in_channels, self.out_channels,\n",
        "                            kernel_size=3, stride=1, padding=1, init_scale=1.0)\n",
        "        self.temb_proj = linear(self.temb_channels, self.out_channels, init_scale=1.0)\n",
        "        self.norm2 = GroupNorm32(self.out_channels)\n",
        "        self.conv2 = conv2d(self.out_channels, self.out_channels,\n",
        "                            kernel_size=3, stride=1, padding=1, init_scale=0.0)\n",
        "\n",
        "        if self.in_channels != self.out_channels:\n",
        "            if self.conv_shortcut:\n",
        "                self.conv_shortcut = nn.Conv2d(self.in_channels, self.out_channels,\n",
        "                                               kernel_size=3, stride=1, padding=1)\n",
        "            else:\n",
        "                self.conv_shortcut = nin(self.in_channels, self.out_channels)\n",
        "        else:\n",
        "            self.conv_shortcut = None\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        h = self.norm1(x)\n",
        "        h = swish(h)\n",
        "        h = self.conv1(h)\n",
        "        h_temb = swish(temb)\n",
        "        h_temb = self.temb_proj(h_temb)  # (B, out_channels)\n",
        "        h_temb = h_temb[:, :, None, None]  # (B, out_channels, 1, 1)\n",
        "        h = h + h_temb\n",
        "        h = self.norm2(h)\n",
        "        h = swish(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        h = self.conv2(h)\n",
        "        if self.conv_shortcut is not None:\n",
        "            x = self.conv_shortcut(x)\n",
        "        return x + h\n"
      ],
      "metadata": {
        "id": "ichVgfOA5Ni3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Train"
      ],
      "metadata": {
        "id": "vbVhEaFfpUwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_beta_alpha(beta_schedule='linear', beta_start=0.0001, beta_end=0.002, num_timesteps=1000):\n",
        "    \"\"\"\n",
        "    Generate values of beta, alpha and bar_alpha.\n",
        …
      ],
      "metadata": {
        "id": "jq6KV6pKnvJy"
      },
      "execution_count": null,
      "outputs": []
    },
    …
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x0 = sample_ddpm(model, shape=(batch_size, 3, 32, 32),\n",
        "                        betas=betas, alphas=alphas, alphas_cumprod=alphas_cumprod,\n",
        "                        device=device)\n",
        "\n",
        "visualize_sample(x0, idx=55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a3546d72e19c484083408a692eb62f57",
            "93cb145e3a8e4d798710bf0bd1af706e",
            "ae7a7904294541b298624bf0430154cb",
            "191108d9e474494180ca978fe79360ff",
            "02485ff7fc1143038b083a966bfa326d",
            "70750ab69b1a4cdba60d8f7e09f423f2",
            "99761b412dde44b1b2f15df2e7e6f4b7",
            "1e9a968a54c140bd80e0c5d1d276f311",
            "001256d77bee494b8b56c34f14ffab83",
            "d58ee704e9684acb8cb0bc831c027531",
            "cd8d85d9b82447f78b0fd79dc049eea2"
          ]
        },
        "id": "AGExeFZqvdZ8",
        "outputId": "0c7b43be-4525-4ff8-e8c0-49a8b2e1b3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          …
        }
      ]
    }
  ]
}
