{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5TZthvihO856",
        "iAH_874YkLMT",
        "e_cbYfz_LUva",
        "ge1W6K1SkOaR",
        "TpYT7RQvYsTx",
        "lcok62SE7OnG"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
        },
        "eee08f14fdf74695bf1e5edd40a46864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2736e8d297b545c09d7e8c6ead7a6d37",
            "placeholder": "​",
            "style": "IPY_MODEL_9c83b461aa224cc3a8c60b73c49a6565",
            "value": "100%"
          }
        },
        "ae3ba473ba9b47a987677369909ad8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_381ec5457fbf4ccd867d068f4f0428f4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a9c5c8ec95d4b51acebdbeb489abb18",
            "value": 10
          }
        },
        "9d029a532b014bb0a7f1584dd343f426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21332c05f06c44da91d7f443a4824c09",
            "placeholder": "​",
            "style": "IPY_MODEL_59bda4aee9164b16922514013ca4e28c",
            "value": " 10/10 [28:25&lt;00:00, 167.15s/it]"
          }
        },
        "76127f30451d46b29473ac2a213c4cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2736e8d297b545c09d7e8c6ead7a6d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c83b461aa224cc3a8c60b73c49a6565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "381ec5457fbf4ccd867d068f4f0428f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9c5c8ec95d4b51acebdbeb489abb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21332c05f06c44da91d7f443a4824c09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59bda4aee9164b16922514013ca4e28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Code Implementation**\n",
        "\n",
        "This code implements PPO algorithm to finetune trained DDPM. <br>\n",
        "Refer to:<br>\n",
        "\n",
        "\n",
        "*   Paper1 : Proximal policy optimization algorithm (2017)\n",
        "*   Paper2 : 3D-HLDM: ... (2024)\n",
        "\n",
        "We have a DDPM model trained with CelebA dataset. Reward model is trained with real dataset of CelebA and fake dataset of synthetic image generated by DDIM. Using this model, we aim to finetune trained DDPM to attain higher reward model score while generating realistic image by sampling process.\n"
      ],
      "metadata": {
        "id": "jROjQUIzDsjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the formula of L_CLIP used in PPO algorithm."
      ],
      "metadata": {
        "id": "gt_jqxNIHlaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$L^{CLIP}(\\theta) = \\hat{\\mathbb{E}}_t \\left[ \\min(r_t(\\theta)\\hat{A}_t, \\mathrm{clip}(r_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A}_t) \\right]$"
      ],
      "metadata": {
        "id": "HkECsi82V-We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We regard the entire reverse process as a single epsiode with a single timestep. $\\hat{A}_t$ in the formula is caculated by the trained reward model and its paramters are fixed during the train. $r_t(\\theta)=\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}$ can be caculated ananlytically using the knowledge of DDPM as in the below."
      ],
      "metadata": {
        "id": "hLIxkcv_HxtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\log r(\\theta) = \\sum_{t=1}^T \\frac{\\Vert x_{t-1} - \\mu_{old}(x_t,t) \\Vert ^2 - \\Vert x_{t-1} - \\mu_\\theta(x_t,t) \\Vert ^2}{2\\tilde{\\beta}_t} $"
      ],
      "metadata": {
        "id": "lJmKbbeaWQwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can compute the value of L_CLIP in each episodes. In each episodes, we iter the entire DDIM reverse process to obtain $r(\\theta)$ and $\\hat{A}$ and backpropagate it. But this method requires too large GPU memory since it preserves all the gradient graph of the whole timestep of the reverse process."
      ],
      "metadata": {
        "id": "mIH9XEN0LLtX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid GPU memory issue, we divide the backpropagation of a single episode into two steps. In the first step, we run the reverse process without gradient calculating, and only saves $x_t$, $\\epsilon_t$ in all timesteps and calculate $\\hat{A}$ with the resulting $x_0$. In the second step, we compute the gradient of $\\log r_t(\\theta)$ and compute the gradient of each timestep. Note that we compute the gradient step by step so that we do not have to save the whole computation graph. This method let us save the GPU memory. Then we can compute the gradient of L_CLIP by the below formula using the gradient of $\\log r_t(\\theta)$. The algorithm is implemented in the function L_CLIP_two_pass."
      ],
      "metadata": {
        "id": "H48ukOKFNBbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\nabla_\\theta L^{CLIP}(\\theta) = \\mathbb{E} \\left[ \\hat{A} r(\\theta) \\sum_{t=1}^T \\nabla_\\theta \\log r_t(\\theta) \\right]$"
      ],
      "metadata": {
        "id": "PCPfwP7LWow_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "5TZthvihO856"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41vpt7NAOr1J",
        "outputId": "2bacc316-f6d9-49d4-d467-749874be5017"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DzLhYWP6aCBt"
      },
      "outputs": [],
      "source": [
        "import os, copy, math, time, random\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import random\n",
        "from torchvision import transforms\n",
        "import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDPM Setup"
      ],
      "metadata": {
        "id": "iAH_874YkLMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "def get_timestep_embedding(t, channel):\n",
        "    half = channel // 2\n",
        "    device = t.device\n",
        "    inv_freq = torch.exp(-math.log(10000) * torch.arange(half) / half).to(device)\n",
        "    args = t.float().unsqueeze(1) * inv_freq.unsqueeze(0)\n",
        "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
        "    return emb\n",
        "\n",
        "class GroupNorm(nn.GroupNorm):\n",
        "    def __init__(self, num_channels, num_groups=8, eps=1e-6):\n",
        "        super().__init__(num_groups, num_channels, eps=eps)\n",
        "\n",
        "def conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True, init_scale=1.0):\n",
        "    conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=bias)\n",
        "    with torch.no_grad():\n",
        "        conv.weight.data *= init_scale\n",
        "    return conv\n",
        "\n",
        "def nin(in_ch, out_ch, init_scale=1.0):\n",
        "    layer = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)\n",
        "    with torch.no_grad():\n",
        "        layer.weight.data *= init_scale\n",
        "    return layer\n",
        "\n",
        "def linear(in_features, out_features, init_scale=1.0):\n",
        "    fc = nn.Linear(in_features, out_features)\n",
        "    with torch.no_grad():\n",
        "        fc.weight.data *= init_scale\n",
        "    return fc\n",
        "\n",
        "class DownsampleBlock(nn.Module):\n",
        "    def __init__(self, channels, with_conv=True):\n",
        "        super().__init__()\n",
        "        if with_conv:\n",
        "            self.op = nn.Conv2d(channels, channels, kernel_size=3, stride=2, padding=1)\n",
        "        else:\n",
        "            self.op = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.op(x)\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, channels, with_conv=True):\n",
        "        super().__init__()\n",
        "        self.with_conv = with_conv\n",
        "        if with_conv:\n",
        "            self.conv = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=2.0, mode='nearest')\n",
        "        if self.with_conv:\n",
        "            x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, temb_channels=256, dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.temb_channels = temb_channels\n",
        "        self.dropout = dropout\n",
        "        self.norm1 = GroupNorm(self.in_channels)\n",
        "        self.conv1 = conv2d(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=1, init_scale=1.0)\n",
        "        self.temb_proj = linear(self.temb_channels, self.out_channels, init_scale=1.0)\n",
        "        self.norm2 = GroupNorm(self.out_channels)\n",
        "        self.conv2 = conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=1, init_scale=1.0)\n",
        "        self.conv_shortcut = nin(self.in_channels, self.out_channels)\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        h = self.norm1(x)\n",
        "        h = swish(h)\n",
        "        h = self.conv1(h)\n",
        "        h_temb = swish(temb)\n",
        "        h_temb = self.temb_proj(h_temb)\n",
        "        h_temb = h_temb[:, :, None, None]\n",
        "        h = h + h_temb\n",
        "        h = self.norm2(h)\n",
        "        h = swish(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        h = self.conv2(h)\n",
        "        x = self.conv_shortcut(x)\n",
        "        return x + h\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.norm = GroupNorm(channels)\n",
        "        self.q = nin(channels, channels)\n",
        "        self.k = nin(channels, channels)\n",
        "        self.v = nin(channels, channels)\n",
        "        self.proj_out = nin(channels, channels, init_scale=0.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.norm(x)\n",
        "        q = self.q(h)\n",
        "        k = self.k(h)\n",
        "        v = self.v(h)\n",
        "        q = q.view(B, C, H * W).permute(0, 2, 1)\n",
        "        k = k.view(B, C, H * W).permute(0, 2, 1)\n",
        "        v = v.view(B, C, H * W).permute(0, 2, 1)\n",
        "        scale = q.shape[-1] ** -0.5\n",
        "        attn = torch.softmax(torch.bmm(q, k.transpose(1, 2)) * scale, dim=-1)\n",
        "        h_ = torch.bmm(attn, v)\n",
        "        h_ = h_.permute(0, 2, 1).reshape(B, C, H, W)\n",
        "        h_ = self.proj_out(h_)\n",
        "        return x + h_\n",
        "\n",
        "class DDPMModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=3,\n",
        "        out_channels=3,\n",
        "        ch=64,\n",
        "        ch_mult=(1, 2, 4),\n",
        "        num_res_blocks=2,\n",
        "        attn_resolutions={32},\n",
        "        dropout=0.0,\n",
        "        resamp_with_conv=False,\n",
        "        init_resolution=64\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.ch = ch\n",
        "        self.ch_mult = ch_mult\n",
        "        self.num_res_blocks = num_res_blocks\n",
        "        self.attn_resolutions = attn_resolutions\n",
        "        self.dropout = dropout\n",
        "        self.num_levels = len(ch_mult)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.resamp_with_conv = resamp_with_conv\n",
        "        self.init_resolution = init_resolution\n",
        "        self.temb_ch = ch * 4\n",
        "        self.temb_dense0 = linear(self.ch, self.temb_ch)\n",
        "        self.temb_dense1 = linear(self.temb_ch, self.temb_ch)\n",
        "        self.conv_in = conv2d(in_channels, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.down_blocks = nn.ModuleList()\n",
        "        curr_ch = ch\n",
        "        curr_res = init_resolution\n",
        "        for level in range(self.num_levels):\n",
        "            level_blocks = nn.ModuleList()\n",
        "            out_ch = ch * ch_mult[level]\n",
        "            for i in range(num_res_blocks):\n",
        "                level_blocks.append(ResnetBlock(curr_ch, out_ch, temb_channels=self.temb_ch, dropout=dropout))\n",
        "                if curr_res in attn_resolutions:\n",
        "                    level_blocks.append(AttnBlock(out_ch))\n",
        "                curr_ch = out_ch\n",
        "            self.down_blocks.append(level_blocks)\n",
        "            if level != self.num_levels - 1:\n",
        "                self.down_blocks.append(DownsampleBlock(curr_ch, with_conv=resamp_with_conv))\n",
        "                curr_res //= 2\n",
        "        self.mid_block = nn.ModuleList([\n",
        "            ResnetBlock(curr_ch, curr_ch, temb_channels=self.temb_ch, dropout=dropout),\n",
        "            AttnBlock(curr_ch),\n",
        "            ResnetBlock(curr_ch, curr_ch, temb_channels=self.temb_ch, dropout=dropout)\n",
        "        ])\n",
        "        self.up_blocks = nn.ModuleList()\n",
        "        for level in reversed(range(self.num_levels)):\n",
        "            level_blocks = nn.ModuleList()\n",
        "            out_ch = ch * ch_mult[level]\n",
        "            level_blocks.append(ResnetBlock(curr_ch + out_ch, out_ch, temb_channels=self.temb_ch, dropout=dropout))\n",
        "            if (init_resolution // (2 ** level)) in attn_resolutions:\n",
        "                level_blocks.append(AttnBlock(out_ch))\n",
        "            curr_ch = out_ch\n",
        "            for i in range(num_res_blocks):\n",
        "                level_blocks.append(ResnetBlock(curr_ch, curr_ch, temb_channels=self.temb_ch, dropout=dropout))\n",
        "                if (init_resolution // (2 ** level)) in attn_resolutions:\n",
        "                    level_blocks.append(AttnBlock(curr_ch))\n",
        "            if level != 0:\n",
        "                level_blocks.append(UpsampleBlock(curr_ch, with_conv=resamp_with_conv))\n",
        "            self.up_blocks.append(level_blocks)\n",
        "        self.norm_out = GroupNorm(curr_ch)\n",
        "        self.conv_out = conv2d(curr_ch, out_channels, kernel_size=3, stride=1, padding=1, init_scale=0.0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        temb = get_timestep_embedding(t, self.ch)\n",
        "        temb = self.temb_dense0(temb)\n",
        "        temb = swish(temb)\n",
        "        temb = self.temb_dense1(temb)\n",
        "        skips = []\n",
        "        h = self.conv_in(x)\n",
        "        down_iter = iter(self.down_blocks)\n",
        "        for level in range(self.num_levels):\n",
        "            blocks = next(down_iter)\n",
        "            for layer in blocks:\n",
        "                h = layer(h, temb) if isinstance(layer, ResnetBlock) else layer(h)\n",
        "            skips.append(h)\n",
        "            if level != self.num_levels - 1:\n",
        "                downsample = next(down_iter)\n",
        "                h = downsample(h)\n",
        "        for layer in self.mid_block:\n",
        "            h = layer(h, temb) if isinstance(layer, ResnetBlock) else layer(h)\n",
        "        for level in range(self.num_levels):\n",
        "            blocks = self.up_blocks[level]\n",
        "            skip = skips.pop()\n",
        "            h = torch.cat([h, skip], dim=1)\n",
        "            h = blocks[0](h, temb)\n",
        "            for layer in blocks[1:]:\n",
        "                if isinstance(layer, ResnetBlock):\n",
        "                    h = layer(h, temb)\n",
        "                else:\n",
        "                    h = layer(h)\n",
        "        h = self.norm_out(h)\n",
        "        h = swish(h)\n",
        "        h = self.conv_out(h)\n",
        "        return h\n",
        "\n",
        "# Sampling\n",
        "def p_sample_ddim(model, x_t, t_cur, t_prev, alphas_cumprod, eta=0.0):\n",
        "    alpha_bar_t = alphas_cumprod[t_cur - 1]\n",
        "    if t_prev > 0:\n",
        "        alpha_bar_prev = alphas_cumprod[t_prev - 1]\n",
        "    else:\n",
        "        alpha_bar_prev = torch.tensor(1.0, device=x_t.device)\n",
        "    sigma_t = eta * torch.sqrt((1 - alpha_bar_prev) / (1 - alpha_bar_t)) * torch.sqrt(1 - alpha_bar_t / alpha_bar_prev)\n",
        "    B = x_t.size(0)\n",
        "    t_tensor = torch.full((B,), t_cur, device=x_t.device, dtype=torch.long)\n",
        "    eps_theta = model(x_t, t_tensor)\n",
        "    sqrt_ab_t = torch.sqrt(alpha_bar_t)\n",
        "    sqrt_ab_prev = torch.sqrt(alpha_bar_prev)\n",
        "    x0_pred = (x_t - torch.sqrt(1 - alpha_bar_t).view(-1, 1, 1, 1) * eps_theta) / sqrt_ab_t.view(-1, 1, 1, 1)\n",
        "    dir_xt = torch.sqrt(torch.clamp(1 - alpha_bar_prev - sigma_t**2, min=0.0)).view(-1, 1, 1, 1) * eps_theta\n",
        "    noise = torch.randn_like(x_t) if t_prev > 0 else torch.zeros_like(x_t)\n",
        "    x_prev = sqrt_ab_prev.view(-1, 1, 1, 1) * x0_pred + dir_xt + sigma_t.view(-1, 1, 1, 1) * noise\n",
        "    return x_prev, eps_theta.detach().cpu(), x_t.detach().cpu()\n",
        "\n",
        "def sample_ddim(model, shape, alphas_cumprod, device, ddim_steps, eta=0.0):\n",
        "    steps_log = {\"t\": [], \"eps_t\": [], \"x_t\": []}\n",
        "    num_timesteps = alphas_cumprod.shape[0]\n",
        "    x = torch.randn(shape, device=device)\n",
        "    idx_lin = torch.linspace(0, num_timesteps - 1, steps=ddim_steps + 1, device=device)\n",
        "    idx0 = idx_lin.round().long()\n",
        "    idx0 = torch.cat([torch.tensor([0, num_timesteps - 1], device=device, dtype=torch.long), idx0]).unique(sorted=True)\n",
        "    seq_asc = idx0 + 1\n",
        "    seq_rev = torch.flip(seq_asc, dims=[0])\n",
        "    seq = torch.cat([seq_rev, torch.tensor([0], device=device, dtype=torch.long)])\n",
        "    prev_t = seq[0].item()\n",
        "    for next_t in seq[1:]:\n",
        "        t_cur = prev_t\n",
        "        t_prev = next_t.item()\n",
        "        x, eps_t, x_t_snap = p_sample_ddim(\n",
        "            model,\n",
        "            x,\n",
        "            t_cur,\n",
        "            t_prev,\n",
        "            alphas_cumprod,\n",
        "            eta\n",
        "        )\n",
        "        steps_log[\"t\"].append(t_cur)\n",
        "        steps_log[\"eps_t\"].append(eps_t)\n",
        "        steps_log[\"x_t\"].append(x_t_snap)\n",
        "        prev_t = t_prev\n",
        "    return x, steps_log\n",
        "\n",
        "# Get alpha_bar\n",
        "def get_beta_alpha_linear(beta_start=0.0001, beta_end=0.02, num_timesteps=1000):\n",
        "    betas = np.linspace(beta_start, beta_end, num_timesteps, dtype=np.float32)\n",
        "    betas = torch.tensor(betas)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "    return betas, alphas, alphas_cumprod"
      ],
      "metadata": {
        "id": "PgaAUJSBkMRE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reward Model"
      ],
      "metadata": {
        "id": "e_cbYfz_LUva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c, kernel=3, stride=1, padding=1, pool=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_c, out_c, kernel, stride, padding, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_c)\n",
        "        self.act = nn.GELU()\n",
        "        self.pool = nn.AvgPool2d(2) if pool else nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class RewardModel(nn.Module):\n",
        "    def __init__(self, in_channels=3, base_channels=32, dropout=0.2):\n",
        "        super().__init__()\n",
        "        b = base_channels\n",
        "        self.blocks = nn.Sequential(\n",
        "            ConvBlock(in_channels, b, pool=True),\n",
        "            ConvBlock(b, b*2, pool=True),\n",
        "            ConvBlock(b*2, b*4, pool=True),\n",
        "            ConvBlock(b*4, b*8, pool=True),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(b*8, 128),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.head(x)\n",
        "        return x.view(-1)"
      ],
      "metadata": {
        "id": "smKScQ9rLWIX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Algorithm"
      ],
      "metadata": {
        "id": "ge1W6K1SkOaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mu_from_eps(x_t, t_idx, eps_pred, alphas, alpha_bars):\n",
        "    \"\"\"\n",
        "    Compute mu(mean) from epsilon which is predicted by model.\n",
        "    The value of mu is used to compute the ratio of the value of policy\n",
        "\n",
        "    Parameters:\n",
        "        x_t (torch.Tensor) : Predicted image tensor at timestep t during the sampling process.\n",
        "        t_idx (int) : Number of the timestep.\n",
        "        eps_pred (torch.Tensor) : The value of epsilon predicted by model.\n",
        "        alphas (torch.Tensor) : Tensor of alphas.\n",
        "        alpha_bars (torch.Tensor) : Tensor of alpha_bars.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor : mu(mean)\n",
        "    \"\"\"\n",
        "    T = alphas.shape[0]\n",
        "    if t_idx < 0:\n",
        "        t_idx = 0\n",
        "    if t_idx > T - 1:\n",
        "        t_idx = T - 1\n",
        "\n",
        "    alpha_t = alphas[t_idx].to(x_t.device, dtype=torch.float32).view(-1, 1, 1, 1)\n",
        "    beta_t  = (1.0 - alphas[t_idx].to(x_t.device, dtype=torch.float32)).view(-1, 1, 1, 1)\n",
        "    abar_t  = alpha_bars[t_idx].to(x_t.device, dtype=torch.float32).view(-1, 1, 1, 1)\n",
        "    denom = torch.sqrt(torch.clamp(1.0 - abar_t, min=1e-12))\n",
        "    num   = beta_t * eps_pred.to(torch.float32)\n",
        "\n",
        "    mu = (x_t.to(torch.float32) - (num / denom)) / torch.sqrt(torch.clamp(alpha_t, min=1e-12))\n",
        "\n",
        "    return mu.to(x_t.dtype)\n",
        "\n",
        "def compute_log_r_sum(cur_model, steps_log, x0_cpu,\n",
        "                      alphas_cumprod, device, eta, eps_to_mu_fn,\n",
        "                      per_step_clip=5.0, global_clip=10.0, sigma_floor=1e-3):\n",
        "    \"\"\"\n",
        "    Compute the log of the sum of the r.\n",
        "    r is the value of the ratio of the policy probability function, as in the PPO algorithm.\n",
        "    This function not only computes log_r_sum, but also the gradients of each parameters.\n",
        "\n",
        "    Parameters:\n",
        "        cur_model (torch.nn.Module) : The model updated most recently.\n",
        "        steps_log (dictionary) : Dictionary of t, x_t, epsilon of each timestep while sampling.\n",
        "        x0_cpu (torch.Tensor) : Image tensor computed by reverse(sampling) process.\n",
        "        alphas_cumprod (torch.Tensor) : Tensor of alpha_bars.\n",
        "        device (torch.device) : Device.\n",
        "        eta (float) : The ratio of probabilistic process in the DDPM(DDIM) reverse process.\n",
        "        eps_to_mu_fn (function) : Function to compute mu(mean) from epsilon.\n",
        "        per_step_clip (float) : Clipping value of log r_t in each timestep.\n",
        "        global_clip (float) : Clipping value of log_r_sum.\n",
        "        simga_floor (float) : Minimum clipping value of sigma to avoid sigma to be too small.\n",
        "\n",
        "    Returns:\n",
        "        float : log_r_sum. Summation is done in each timestep.\n",
        "        list of tensors : sum_grads. List of gradients of each parameters. Summation is done in each timestep.\n",
        "    \"\"\"\n",
        "    params = [p for p in cur_model.parameters() if p.requires_grad]\n",
        "    sum_grads = [torch.zeros_like(p) for p in params]\n",
        "    log_r_sum = 0.0\n",
        "\n",
        "    Tlist = steps_log[\"t\"]\n",
        "    Xlist = steps_log[\"x_t\"]\n",
        "    Elist = steps_log[\"eps_t\"]\n",
        "\n",
        "    total_steps = len(Tlist)\n",
        "\n",
        "    # Iter each step and compute r in each step.\n",
        "    for k in range(total_steps):\n",
        "        t_cur  = int(Tlist[k])\n",
        "        t_prev = int(Tlist[k+1]) if (k+1) < total_steps else 0\n",
        "\n",
        "        # Skip deterministic last-step\n",
        "        if t_prev == 0:\n",
        "            continue\n",
        "\n",
        "        # Load data on GPU\n",
        "        x_t = Xlist[k].to(device).detach()\n",
        "        x_tprev = Xlist[k+1].to(device).detach() if (k+1)<len(Xlist) else x0_cpu.to(device).detach()\n",
        "        eps_old = Elist[k].to(device).detach()\n",
        "\n",
        "        # Compute mu_old. mu_old is computed by eps_old which is computed by old_model.\n",
        "        mu_old = eps_to_mu_fn(x_t, t_cur-1, eps_old).detach()\n",
        "\n",
        "        # Compute mu_cur. mu_cur is computed by eps_cur which is computed by cur_model.\n",
        "        t_tensor = torch.full((x_t.size(0),), t_cur, device=device, dtype=torch.long)\n",
        "        eps_cur  = cur_model(x_t, t_tensor)  # requires_grad=True\n",
        "        mu_cur = eps_to_mu_fn(x_t, t_cur-1, eps_cur)\n",
        "\n",
        "        # Compute sigma_t to use in DDIM sampling steps.\n",
        "        a_t = alphas_cumprod[t_cur-1].to(device).float()\n",
        "        if t_prev > 0:\n",
        "            a_prev = alphas_cumprod[t_prev-1].to(device).float()\n",
        "            num = torch.clamp(1.0-a_prev, min=0.0)\n",
        "            denom = torch.clamp(1.0-a_t, min=1e-12)\n",
        "            frac = torch.clamp(num/denom,  min=0.0, max=1.0)\n",
        "            term = torch.clamp(1.0 - (a_t/a_prev), min=0.0)\n",
        "            c1 = torch.sqrt(frac)\n",
        "            c2 = torch.sqrt(term)\n",
        "        else:\n",
        "            c1 = torch.tensor(1.0, device=device, dtype=torch.float32)\n",
        "            c2 = torch.tensor(0.0, device=device, dtype=torch.float32)\n",
        "        sigma_t = (eta * c1 * c2).to(x_t.dtype)\n",
        "        sigma_t = torch.clamp(sigma_t, min=float(sigma_floor))\n",
        "\n",
        "        # Compute log r_t.\n",
        "        diff_cur = (x_tprev - mu_cur).pow(2).mean() # Use mean so that the scale of the value is preserved.\n",
        "        diff_old = (x_tprev - mu_old).pow(2).mean()\n",
        "        denom = 2.0 * (sigma_t**2) + 1e-12\n",
        "        log_r_t  = - (diff_cur-diff_old) / denom\n",
        "\n",
        "        # Clamp before autodiff to avoid exploding grads.\n",
        "        log_r_t_clamped = torch.clamp(log_r_t, -per_step_clip, per_step_clip)\n",
        "\n",
        "        # Compute grads on clamped log value.\n",
        "        grads_t = torch.autograd.grad(log_r_t_clamped, params, retain_graph=False, allow_unused=True)\n",
        "\n",
        "        # Accumulate detached grads.\n",
        "        for j, g in enumerate(grads_t):\n",
        "            if (g is not None) and torch.isfinite(g).all().item():\n",
        "                sum_grads[j].add_(g.detach())\n",
        "\n",
        "        # Numeric accumulation (sum of clamped logs).\n",
        "        log_r_sum += float(log_r_t_clamped.detach().cpu().item())\n",
        "\n",
        "        # Cleanup local tensors.\n",
        "        del x_t, x_tprev, eps_old, mu_old, eps_cur, mu_cur, diff_cur, diff_old, log_r_t, log_r_t_clamped, grads_t\n",
        "\n",
        "    # Clamp computed log_r_sum.\n",
        "    log_r_sum = max(min(log_r_sum, float(global_clip)), -float(global_clip))\n",
        "\n",
        "    return float(log_r_sum), sum_grads\n",
        "\n",
        "def L_CLIP_two_pass(old_model, cur_model, rm, alphas_cumprod, device, shape,\n",
        "                    ddim_steps, eta, eps_to_mu_fn, clip_eps, n_episodes,\n",
        "                    optimizer, grad_clip=1.0,\n",
        "                    microbatch=1, per_step_clip=5.0, global_clip=10.0, sigma_floor=1e-3):\n",
        "    \"\"\"\n",
        "    Run episodes and backpropagate the loss.\n",
        "    The process is consists of two passes.\n",
        "    1)\n",
        "\n",
        "    Parameters:\n",
        "        old_model (torch.nn.Module) : The fixed model updated in the previous epoch.\n",
        "        cur_model (torch.nn.Module) : The model updated most recently. Parameters of cur_model keeps updated in each episodes.\n",
        "        rm (torch.nn.Module) : Reward model.\n",
        "        alphas_cumprod (torch.Tensor) : Tensor of alpha_bars.\n",
        "        device (torch.device) : Device.\n",
        "        shape (tuple) : Shape of the image.\n",
        "        ddim_steps (int) : Number of steps in DDIM sampling process.\n",
        "        eta (float) : The ratio of probabilistic process in the DDPM(DDIM) reverse process.\n",
        "        eps_to_mu_fn (function) : Function to compute mu(mean) from epsilon.\n",
        "        clip_eps (float) : Clipping value of log(r_t)*A_t in the PPO.\n",
        "        n_episodes (int) : Number of episodes executed in each epoch.\n",
        "        optimizer (torch.nn.optim) : Optimizer to update parameters of cur_model.\n",
        "        grad_clip (float) :\n",
        "        microbatch (int) : Number of episodes executed in each epoch.\n",
        "        per_step_clip (float) : Clipping value of log r_t in each timestep.\n",
        "        global_clip (float) : Clipping value of log_r_sum.\n",
        "        simga_floor (float) : Minimum clipping value of sigma to avoid sigma to be too small.\n",
        "\n",
        "    Returns:\n",
        "        float : avg_loss_per_mb.\n",
        "        dictionary : stats. Has the information about the current epoch.\n",
        "    \"\"\"\n",
        "    # Get old_model, rm and fix their parameters.\n",
        "    old_model.eval()\n",
        "    rm.eval()\n",
        "    for p in old_model.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in rm.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    # Pass 1\n",
        "    buffers = [] # saves steps_log(t,x_t,eps_t) and x0_cpu in each episodes.\n",
        "    rewards_list = [] # saves total reward(float) in each episodes.\n",
        "\n",
        "    # Iter episodes.\n",
        "    for _ in range(n_episodes):\n",
        "        with torch.no_grad():\n",
        "            # Execute reverese process and get x0 and steps_log.\n",
        "            x0, steps_log = sample_ddim(\n",
        "                model=old_model, shape=shape,\n",
        "                alphas_cumprod=alphas_cumprod, device=device,\n",
        "                ddim_steps=ddim_steps, eta=eta\n",
        "            )\n",
        "\n",
        "            # Get steps_log_cpu, x0_cpu to save in the buffers list.\n",
        "            x0_cpu = x0.detach().cpu()\n",
        "            Tlist = steps_log[\"t\"]\n",
        "            Xlist = [xt.detach().cpu() for xt in steps_log[\"x_t\"]]\n",
        "            Elist = [et.detach().cpu() for et in steps_log[\"eps_t\"]]\n",
        "            steps_log_cpu = {\"t\": Tlist, \"x_t\": Xlist, \"eps_t\": Elist}\n",
        "\n",
        "            # Get reward from the trained reward model.\n",
        "            R_t = rm(x0_cpu.to(device)).mean()\n",
        "            R = float(R_t.item())\n",
        "\n",
        "        buffers.append((steps_log_cpu, x0_cpu))\n",
        "        rewards_list.append(R)\n",
        "\n",
        "    # Make it be a tensor.\n",
        "    rewards = torch.tensor(rewards_list, device=device, dtype=torch.float32)\n",
        "    advantages = rewards.detach()\n",
        "\n",
        "    # Prepare training.\n",
        "    cur_model.train()\n",
        "    total_loss_val = 0.0\n",
        "    clip_cnt = 0\n",
        "    sample_cnt = 0\n",
        "    valid_n = len(buffers)\n",
        "\n",
        "    # Pass 2\n",
        "    for i in range(0, valid_n, microbatch):\n",
        "        # Get microbatch number of episodes.\n",
        "        mb = buffers[i:i+microbatch]\n",
        "        adv_mb = advantages[i:i+microbatch]\n",
        "\n",
        "        # Set optimizer.\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        params = [p for p in cur_model.parameters() if p.requires_grad]\n",
        "\n",
        "        for (steps_log_cpu, x0_cpu), adv in zip(mb, adv_mb):\n",
        "            # Compute log_r_val and sum_grads in current microbatch.\n",
        "            log_r_val, sum_grads = compute_log_r_sum(\n",
        "                cur_model=cur_model,\n",
        "                steps_log=steps_log_cpu,\n",
        "                x0_cpu=x0_cpu,\n",
        "                alphas_cumprod=alphas_cumprod,\n",
        "                device=device,\n",
        "                eta=eta,\n",
        "                eps_to_mu_fn=eps_to_mu_fn,\n",
        "                per_step_clip=per_step_clip,\n",
        "                global_clip=global_clip,\n",
        "                sigma_floor=sigma_floor\n",
        "            )\n",
        "\n",
        "            # Get r_val and A(advantage).\n",
        "            r_val = math.exp(log_r_val)\n",
        "            A = float(adv.item())\n",
        "\n",
        "            # Clip r_val as in the PPO algorithm.\n",
        "            low, high = 1.0 - clip_eps, 1.0 + clip_eps\n",
        "            rc = min(max(r_val, low), high)  # rc : r_clipped\n",
        "\n",
        "            # loss = -min(r*A, rc*A)\n",
        "            val  = r_val * A # val denotes the value of objective function in PPO algorithm.\n",
        "            valc = rc    * A # valc : val_clipped\n",
        "            chosen = val if val < valc else valc\n",
        "            s = -chosen # We will use loss function, not an objective function, so multiply -1.\n",
        "\n",
        "            # Count the number of clipped episodes in current microbatch.\n",
        "            unclipped = (A >= 0 and r_val <= high) or (A < 0 and r_val >= low)\n",
        "            if not unclipped:\n",
        "                clip_cnt += 1\n",
        "            sample_cnt += 1\n",
        "\n",
        "            # Execute backpropagation only if the value is unclipped.\n",
        "            if unclipped:\n",
        "                # We want to compute (d/d_theta)(r_val)*A which is same as A*r_val*(d/d_theta)(log(r_val))\n",
        "                # The value of (d/d_theta)(log(r_val)) is sum_grads, computed in the function compute_log_r_sum.\n",
        "                scale = -A * r_val / float(microbatch)\n",
        "                for p, g in zip(params, sum_grads):\n",
        "                    grad_to_apply = (g.detach().clone().to(p.device)) * float(scale)\n",
        "                    if p.grad is None:\n",
        "                        p.grad = grad_to_apply\n",
        "                    else:\n",
        "                        p.grad.add_(grad_to_apply)\n",
        "\n",
        "        # Gradient clip and optimizer step.\n",
        "        total_norm = torch.nn.utils.clip_grad_norm_(cur_model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    # Return the log of single epoch.\n",
        "    clip_frac = (clip_cnt / sample_cnt) if sample_cnt > 0 else float(\"nan\")\n",
        "    stats = {\n",
        "        \"reward_mean\": float(rewards.mean().item()),\n",
        "        \"reward_std\": float(rewards.std(unbiased=False).item()),\n",
        "        \"episodes\": int(valid_n),\n",
        "        \"microbatch\": microbatch,\n",
        "        \"ddim\": ddim_steps,\n",
        "        \"eta\": eta,\n",
        "        \"clip\": clip_eps,\n",
        "        \"clip_frac\": float(clip_frac)\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "def single_epoch(ddpm_cur, ddpm_old, rm, alphas_cumprod, device, shape, optimizer,\n",
        "                 eps_to_mu_fn, ddim_steps=100, eta=1.0, clip_eps=0.1,\n",
        "                 episodes_per_epoch=30, normalize_rewards=True, grad_clip=1.0,\n",
        "                 microbatch=1):\n",
        "    \"\"\"\n",
        "    Run a single epoch.\n",
        "\n",
        "    Parameters:\n",
        "        ddpm_cur (torch.nn.Module) : The model updated most recently.\n",
        "        ddpm_old (torch.nn.Module) : The fixed model updated in the previous epoch.\n",
        "        rm (torch.nn.Module) : Reward model.\n",
        "        alphas_cumprod (torch.Tensor) : Tensor of alpha_bars.\n",
        "        device (torch.device) : Device.\n",
        "        shape (tuple) : Shape of the image.\n",
        "        optimizer (torch.nn.optim) : Optimizer to update parameters of cur_model.\n",
        "        eps_to_mu_fn (function) : Function to compute mu(mean) from epsilon.\n",
        "        ddim_steps (int) : Number of steps in DDIM sampling process.\n",
        "        eta (float) : The ratio of probabilistic process in the DDPM(DDIM) reverse process.\n",
        "        clip_eps (float) : Clipping value of log(r_t)*A_t in the PPO\n",
        "        episodes_per_epoch (int) : Number of episodes executed in each epoch.\n",
        "        normalize_rewards (bool) : Whether to normalize rewards.\n",
        "        grad_clip (float) :\n",
        "        microbatch (int) : Number of episodes executed in each epoch.\n",
        "\n",
        "    Returns:\n",
        "        dictionary : stats. Has the information about the current epoch.\n",
        "    \"\"\"\n",
        "    ddpm_old.eval()\n",
        "    for p in ddpm_old.parameters(): p.requires_grad = False\n",
        "    rm.eval()\n",
        "    for p in rm.parameters(): p.requires_grad = False\n",
        "\n",
        "    stats = L_CLIP_two_pass(\n",
        "        old_model=ddpm_old,\n",
        "        cur_model=ddpm_cur,\n",
        "        rm=rm,\n",
        "        alphas_cumprod=alphas_cumprod,\n",
        "        device=device,\n",
        "        shape=shape,\n",
        "        ddim_steps=ddim_steps,\n",
        "        eta=eta,\n",
        "        eps_to_mu_fn=eps_to_mu_fn,\n",
        "        clip_eps=clip_eps,\n",
        "        n_episodes=episodes_per_epoch,\n",
        "        optimizer=optimizer,\n",
        "        grad_clip=grad_clip,\n",
        "        microbatch=microbatch\n",
        "    )\n",
        "    stats.update({\"ddim_steps\": ddim_steps, \"eta\": eta, \"clip_eps\": clip_eps})\n",
        "    return stats"
      ],
      "metadata": {
        "id": "flJDCgbfXLWi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train setup"
      ],
      "metadata": {
        "id": "TpYT7RQvYsTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "ddpm_cur = DDPMModel().to(device)\n",
        "ckpt_path = '/content/drive/MyDrive/cv프로젝트/부트캠프/_100.pth'\n",
        "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "state_dict = checkpoint[\"model_state_dict\"] if \"model_state_dict\" in checkpoint else checkpoint\n",
        "ddpm_cur.load_state_dict(state_dict)\n",
        "print(f\"Loaded base DDPM from {ckpt_path}\")\n",
        "\n",
        "ddpm_old = copy.deepcopy(ddpm_cur).to(device)\n",
        "for p in ddpm_old.parameters():\n",
        "    p.requires_grad = False\n",
        "ddpm_old.eval()\n",
        "\n",
        "rm = RewardModel().to(device)\n",
        "rm_ckpt_path = '/content/drive/MyDrive/논문코드리뷰/논문코드리뷰_PPO/reward_model_v2.pt'\n",
        "rm_state = torch.load(rm_ckpt_path, map_location=\"cpu\")\n",
        "rm.load_state_dict(rm_state[\"model_state_dict\"] if \"model_state_dict\" in rm_state else rm_state)\n",
        "rm.eval()\n",
        "for p in rm.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "betas, alphas, alpha_bars = get_beta_alpha_linear()\n",
        "alphas = alphas.to(device)\n",
        "alpha_bars = alpha_bars.to(device)\n",
        "\n",
        "eps_to_mu_fn = lambda x_t, t_idx, eps_pred: compute_mu_from_eps(\n",
        "    x_t, t_idx, eps_pred, alphas, alpha_bars\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(ddpm_cur.parameters(), lr=1e-6)\n",
        "\n",
        "# Parameters\n",
        "epochs               = 10\n",
        "episodes_per_epoch   = 10\n",
        "ddim_steps           = 200\n",
        "eta                  = 0.5 # Sampling process is not deterministic.\n",
        "clip_eps             = 0.2\n",
        "normalize_rewards    = False\n",
        "grad_clip            = 1.0\n",
        "microbatch           = 1\n",
        "\n",
        "# Shape\n",
        "B = 1\n",
        "C = ddpm_cur.in_channels\n",
        "H = W = ddpm_cur.init_resolution\n",
        "shape = (B, C, H, W)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_with_cur_model(cur_model, rm, alphas_cumprod, device, ddim_steps=200, eta=0.5, n_eval=8):\n",
        "    # Get rewards of the image generated by cur_model.\n",
        "    cur_model.eval()\n",
        "    x0, _ = sample_ddim(model=cur_model, shape=(8,3,64,64), alphas_cumprod=alphas_cumprod,\n",
        "                        device=device, ddim_steps=ddim_steps, eta=eta)\n",
        "    return rm(x0).mean().item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBm0YECfKN5M",
        "outputId": "c3323515-636f-468b-e788-0ccdaadb27a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Loaded base DDPM from /content/drive/MyDrive/cv프로젝트/부트캠프/_100.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "lcok62SE7OnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(1, epochs + 1)):\n",
        "    # Execute single epoch.\n",
        "    stats = single_epoch(\n",
        "        ddpm_cur=ddpm_cur,\n",
        "        ddpm_old=ddpm_old,\n",
        "        rm=rm,\n",
        "        alphas_cumprod=alpha_bars,\n",
        "        device=device,\n",
        "        shape=shape,\n",
        "        optimizer=optimizer,\n",
        "        eps_to_mu_fn=eps_to_mu_fn,\n",
        "        ddim_steps=ddim_steps,\n",
        "        eta=eta,\n",
        "        clip_eps=clip_eps,\n",
        "        episodes_per_epoch=episodes_per_epoch,\n",
        "        grad_clip=grad_clip,\n",
        "        microbatch=microbatch\n",
        "    )\n",
        "\n",
        "    # Compute reward of the image generated by recently updated model.\n",
        "    cur_eval_mean = eval_with_cur_model(ddpm_cur, rm, alpha_bars, device,\n",
        "                                                      ddim_steps=ddim_steps, eta=eta, n_eval=8)\n",
        "\n",
        "    # Print log.\n",
        "    print(f\"[Epoch {epoch}/{epochs}] \"\n",
        "          f\"reward_mean(old)={stats['reward_mean']:.4f} ± {stats['reward_std']:.4f} | \"\n",
        "          f\"cur_eval={cur_eval_mean:.4f} | \"\n",
        "          f\"clip_frac={stats.get('clip_frac', float('nan')):.2f} | \"\n",
        "          f\"episodes={stats['episodes']} | mb={stats['microbatch']} | \"\n",
        "          f\"ddim={stats['ddim_steps']} | eta={stats['eta']} | clip={stats['clip_eps']} | \")\n",
        "\n",
        "    # Set ddpm_old as ddpm_cur and fix it for the next epoch.\n",
        "    ddpm_old.load_state_dict(ddpm_cur.state_dict())\n",
        "    ddpm_old.eval()\n",
        "    for p in ddpm_old.parameters():\n",
        "        p.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "de127a46e1da4a8a96e1a833dfa39a61",
            "eee08f14fdf74695bf1e5edd40a46864",
            "ae3ba473ba9b47a987677369909ad8c6",
            "9d029a532b014bb0a7f1584dd343f426",
            "76127f30451d46b29473ac2a213c4cfd",
            "2736e8d297b545c09d7e8c6ead7a6d37",
            "9c83b461aa224cc3a8c60b73c49a6565",
            "381ec5457fbf4ccd867d068f4f0428f4",
            "3a9c5c8ec95d4b51acebdbeb489abb18",
            "21332c05f06c44da91d7f443a4824c09",
            "59bda4aee9164b16922514013ca4e28c"
          ]
        },
        "id": "KcJefcMJ7N3V",
        "outputId": "dac2cc43-bc13-4343-9de4-46ae2af5ee43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de127a46e1da4a8a96e1a833dfa39a61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/10] reward_mean(old)=0.6976 ± 0.5925 | cur_eval=-0.4406 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 2/10] reward_mean(old)=-0.0157 ± 0.5406 | cur_eval=0.9784 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 3/10] reward_mean(old)=0.3404 ± 0.7218 | cur_eval=-0.2075 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 4/10] reward_mean(old)=0.1421 ± 0.9821 | cur_eval=0.3079 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 5/10] reward_mean(old)=0.5552 ± 0.7723 | cur_eval=0.3439 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 6/10] reward_mean(old)=0.6256 ± 0.9455 | cur_eval=0.5896 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 7/10] reward_mean(old)=-0.1001 ± 0.7877 | cur_eval=0.2642 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 8/10] reward_mean(old)=0.0699 ± 0.7301 | cur_eval=0.6921 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 9/10] reward_mean(old)=0.4544 ± 0.8626 | cur_eval=0.4939 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n",
            "[Epoch 10/10] reward_mean(old)=0.5063 ± 1.0931 | cur_eval=-0.0788 | clip_frac=0.00 | episodes=10 | mb=1 | ddim=200 | eta=0.5 | clip=0.2 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show\n",
        "Human image is well generated also by finetuned DDPM model."
      ],
      "metadata": {
        "id": "v74QJY1naoWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_cur.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x0,_ = sample_ddim(\n",
        "        model=ddpm_cur,\n",
        "        shape=shape,\n",
        "        alphas_cumprod=alpha_bars,\n",
        "        device=device,\n",
        "        ddim_steps=ddim_steps,\n",
        "        eta=eta\n",
        "    )\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize_sample(x0, idx=0):\n",
        "    img = x0[idx]\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img = (img + 1.0) / 2.0\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Sampled x_0\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_sample(x0.cpu(),idx=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "PghJWuC0aaaR",
        "outputId": "9b15ee37-d841-47ff-ef06-355ff00a53c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAFeCAYAAADnm4a1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP+tJREFUeJztvVusXtV19j/etd7jPnhv29hm2+GQlIALX1C/L1iI3kQNDUghQa1KJS7aGlJIpRBS0YtIPYJIIpFWqolAQqEqVGpu2hwqUYWEKhWoVUmlhhRK9H1NW0ycBPB57+19eM9r/i9I/M+a4zfxxLglJM9PQuKdXoe51pprenk8c4ynEUIIJoQQwlG82R0QQogfVzRBCiFEAk2QQgiRQBOkEEIk0AQphBAJNEEKIUQCTZBCCJFAE6QQQiTQBCmEEAk0QYo3lUajYffcc885O95TTz1ljUbDnnrqqXN2TPHTiybInwCef/55u+mmm+yiiy6ybrdre/bssfe97332wAMPvNld+6nhz//8z+1nf/Znrdvt2jvf+U7d+58QNEG+xXn66aftqquusueee85uv/12e/DBB+22226zoijsM5/5zJvdvZ8KPvvZz9ptt91mV1xxhT3wwAN2zTXX2Mc+9jH79Kc//WZ3TbxBmm92B8Qb41Of+pQtLCzYv/zLv9ji4mLtz44ePfrmdOqniH6/b7//+79vN9xwg33hC18wM7Pbb7/dqqqyT3ziE/bhD3/Ytm7d+ib3Upwt+oJ8i/PCCy/YFVdc4SZHM7OdO3fWfj/66KP23ve+13bu3GmdTscuv/xye+ihh9x+F198sX3gAx+wp556yq666irr9Xr2rne963Rc70tf+pK9613vsm63a+9+97vtX//1X2v733LLLTY3N2cHDx6066+/3mZnZ2337t127733Wk7xqJdeesk+9KEP2a5du6zT6dgVV1xhjzzyiNvu+9//vv3SL/2Szc7O2s6dO+2uu+6y4XB4xuP3+33bu3ev7d271/r9/un2kydP2tLSkv38z/+8TafTMx7HzOzJJ5+0EydO2Ec+8pFa+x133GEbGxv25S9/Oes44seUIN7SXHfddWF+fj48//zzZ9x237594ZZbbgkHDhwIDzzwQLjuuuuCmYUHH3ywtt1FF10ULrvssrC0tBTuueeecODAgbBnz54wNzcXPve5z4ULL7ww3HfffeG+++4LCwsL4ZJLLgnT6fT0/vv37w/dbje8853vDL/+678eHnzwwfCBD3wgmFn4wz/8w9q5zCzcfffdp38fPnw4vO1tbwsXXHBBuPfee8NDDz0UbrzxxmBm4cCBA6e329zcDJdeemnodrvh4x//eLj//vvDu9/97nDllVcGMwtPPvnka96Lf/7nfw5lWYa77rrrdNvNN98cer1e+Pa3v33Ge/lDPvnJTwYzC0eOHKm1D4fDUBRF+J3f+Z3sY4kfPzRBvsX5u7/7u1CWZSjLMlxzzTXh4x//eHjiiSfCaDRy225ubrq266+/PrzjHe+otV100UXBzMLTTz99uu2JJ54IZhZ6vV44dOjQ6fbPfvazbkLav39/MLNw5513nm6rqirccMMNod1uh2PHjp1ujyfI3/zN3wxLS0vh+PHjtT7dfPPNYWFh4fQ13H///cHMwl//9V+f3mZjYyNccsklWRNkCCH87u/+biiKIvzDP/xD+PznPx/MLNx///1n3O9HueOOO0JZlvhnO3bsCDfffPPrOp748UL/xH6L8773vc++/vWv24033mjPPfec/fEf/7Fdf/31tmfPHnvsscdq2/Z6vdP/v7q6asePH7f3vOc9dvDgQVtdXa1te/nll9s111xz+vfVV19tZmbvfe977cILL3TtBw8edH376Ec/evr/G42GffSjH7XRaGRf+9rX8FpCCPbFL37RPvjBD1oIwY4fP376v+uvv95WV1ftm9/8ppmZPf7447a0tGQ33XTT6f1nZmbswx/+8GvfsB/hnnvusSuuuML2799vH/nIR+w973mPfexjH8ve3+zVf6632238s263W/snvHjrIZHmJ4B9+/bZl770JRuNRvbcc8/Z3/zN39iBAwfspptusmeffdYuv/xyMzP7p3/6J7v77rvt61//um1ubtaOsbq6agsLC6d//+gkaGan/+yCCy7A9uXl5Vp7URT2jne8o9Z26aWXmpnZd77zHbyOY8eO2crKij388MP28MMP4zY/FJ4OHTpkl1xyiTUajdqfX3bZZbgf0W637ZFHHrF9+/ZZt9u1Rx991B3vTPR6PRuNRvhng8Gg9peSeOuhCfIniHa7bfv27bN9+/bZpZdearfeeqt9/vOft7vvvtteeOEFu/baa23v3r32p3/6p3bBBRdYu922xx9/3A4cOGBVVdWOVZYlniPVHs6Bc8cP+/Brv/Zrtn//ftzmyiuvfMPn+VGeeOIJM3t1MvvP//xPe/vb3/669l9aWrLpdGpHjx6tiWKj0chOnDhhu3fvPqf9Ff+zaIL8CeWqq64yM7NXXnnFzMz+9m//1obDoT322GO1r8Mnn3zyv+X8VVXZwYMHT381mpn9x3/8h5m9qpITO3bssPn5eZtOp/aLv/iLr3n8iy66yL71rW9ZCKH21fftb387u4//9m//Zvfee6/deuut9uyzz9ptt91mzz//fO1L+kz83M/9nJmZfeMb37D3v//9p9u/8Y1vWFVVp/9cvDVRDPItzpNPPolfb48//riZ/f//5Pzhl9+Pbru6umqPPvrof1vfHnzwwdP/H0KwBx980Fqtll177bW4fVmW9iu/8iv2xS9+0b71rW+5Pz927Njp/3//+99vL7/88um1h2Zmm5ubyX+ax4zHY7vlllts9+7d9pnPfMb+4i/+wo4cOWJ33XVX7uWZ2asx2W3btrnlUg899JDNzMzYDTfc8LqOJ3680BfkW5w777zTNjc37Zd/+Zdt7969NhqN7Omnn7a/+qu/sosvvthuvfVWMzO77rrrrN1u2wc/+EH7rd/6LVtfX7c/+7M/s507d57+yjyXdLtd++pXv2r79++3q6++2r7yla/Yl7/8Zfu93/s927FjR3K/++67z5588km7+uqr7fbbb7fLL7/cTp48ad/85jfta1/7mp08edLM7HTW0G/8xm/YM888Y0tLS/aXf/mXNjMzk9W/T37yk/bss8/a3//939v8/LxdeeWV9kd/9Ef2B3/wB3bTTTfVvgZfi16vZ5/4xCfsjjvusF/91V+166+/3v7xH//RPve5z9mnPvUp27ZtW9ZxxI8pb6KCLs4BX/nKV8KHPvShsHfv3jA3Nxfa7Xa45JJLwp133unW5j322GPhyiuvDN1uN1x88cXh05/+dHjkkUeCmYUXX3zx9HYXXXRRuOGGG9y5zCzccccdtbYXX3wxmFn4kz/5k9Nt+/fvD7Ozs+GFF14I1113XZiZmQm7du0Kd999d2295A+P+aPLfEII4ciRI+GOO+4IF1xwQWi1WuH8888P1157bXj44Ydr2x06dCjceOONYWZmJpx33nnht3/7t8NXv/rVMy7zeeaZZ0Kz2awtQwohhMlkEvbt2xd2794dlpeXk/sTDz/8cLjssstCu90OP/MzPxMOHDgQqqp6XccQP340QpAvtji33HLLLfaFL3zB1tfX3+yuCPGGUAxSCCESKAYpBDAajU7HO1MsLCxoneNPOJoghQCefvpp+4Vf+IXX3ObRRx+1W2655X+mQ+JNQTFIIYDl5WV75plnXnObK664wpaWlv6HeiTeDDRBCiFEAok0QgiRQBOkEEIkyBZprnrb+a4tVL7qcqiif7FPK7eNwb/q+V/6ft94Ri+Dr77SMKjIAsevDPoBvbDoeFTvZQrHH0FV6gG0DaO2CfbVE+DaQ4PuLewcb3OO23IImXvm1NehIzUa/u9/OhYeP6NrtF8B1YC4QJA/QSN6dvT1QseiCkQF7NyIjkj7lXBVXbiPiy1f4m2u1ar3AY4VF0UxM5vAvR7DiKf3tRG9AwUcP8B1/uOJ116hcPp4WVsJIcRPIZoghRAigSZIIYRIoAlSCCES5GfSkLCCYepou9wI+Dlcjtmg41NwG/Yl4YBkoBgKSJcFtIGwUlRRW/a9oPvom+IYNQoaeCi68rN7TjxWcvfNHXt+Kw8IW3hJ4TV/8pG4r9liS7xr7i0jTRI2C5Hw0QDlj4QtGLIomMTDGL++sucDaKK2SJSpaCMQbnLRF6QQQiTQBCmEEAk0QQohRAJNkEIIkSBbpIkTZF7lLNMNMlUCyq6JmyhzxALN+7niAgTxo9+5wecCAt4lRMZjLYeyMSj4jBkaGfFuvGWUjcHpKbQzbOh2hCYI9OfF650YwplG1I3cAXnmLUiwKuheZL8D0YZ4W0E4AzGw2fSvdjNKrylhfDahX016KLBvvBk+N0ys81tSZtqUxJZoOxrbZ53qZfqCFEKIJJoghRAigSZIIYRIkB2DjCuNmHE1mXjKbcSrR8180M3MrzJ9tRHOWe9HgP1wsffZlmx5de/X/Gnmq4q8ek5adE7bxX9P+Yo/eHcyu++7AX3IXpuet3o5vk66bho/PM788eM7xAvYMys9ZRR/4nAgxQMh7lxCrI+2K+J75plUEzhn6do6Xe+V0y7r23VLiFPSMxn78VhAVaqG1Y9PsXR852ggQ7yxggBmlRP4fAPoC1IIIRJoghRCiASaIIUQIoEmSCGESJAt0nBA3W/n1rpCABkD/WQf4OPANo3C87jwNDNSmy/RnLnMClacgc7l9C17KTOKC3nCUM45s8vE5OyZqQJxVSGPFwDyzBQKEghRQIrEQFqKTouqQfjotL09Qafdcm3tVryvP8HG5oZrK0r/jpXw3sWVb6bV2G3ThP0wcQGElXjBerP01zgB8YWEXHpPaN9xXM0nV7nMRF+QQgiRQBOkEEIk0AQphBAJNEEKIUSCfJEGsjuookccA0fPXtwPgsoBAsbjemC5glX+JNzklswnXFYI+VZnVB5KdMNXpkGVhgLZJAKd+Zz5WSe0WV5GFVZZOkO/Um05lXryrogtBTrtjmtrRsIHHX8y9iIHiWTVFDzTh37fKspOoQwc6j9looyHI9dWRKonVtGB97UJ31EFPJRxtGsLBDF6llO4u7H4YpbwlK/qbXT8s7UJMdMXpBBCJNEEKYQQCTRBCiFEAk2QQgiRIFukmUAguEkB+6iME1R1QuEGy0RltFWFL/8UJiDcTDJKJRlncricDRKe/G6caQSB60ZsEUGBfrQnoCD4maUPFC+yzbLPzrKAQAvjzOygPPdy2ApP4Jvm5uZqv0nIGfSHrm0y8eLItPLjsZrSeKy3hQBjm/bDjC1PM/LQyPa7BgsTsmuYRiJQf+zvBY2eEQgyfRBkBnAfxyH2xfbH51KHeegLUgghEmiCFEKIBJoghRAigSZIIYRI8Dp8sSE4DCHXOPeFxJdc8YLKLDXa9eM1wP83QHbNeARZDyMIgmdEeQsoCYWCEgSyMQtnUu/bFALUFQhP04nvf5yNYUalu4g8wSo74ybDBwflpLP1XwewzBucYAzCytraWu13sYXGcV72FGdxwb7O+iivXFuY5pUiLKIx2oRKhCX0i7yy21DWrYy+t8aQaURi7wjahiDcjCBNZhrdIyqT9ka+AvUFKYQQCTRBCiFEAk2QQgiRID8GCf/+p4XWVbwYFY5FFUmwEn5GXLKgiicQHyHrh2B+oe+Y4pLRRVA1IjpnCaXwO7TANoqjDvsDvw2Ux5/CQ6HKKK4ls8oQr689Wy/xnKXdrwPnW33mmJ4ZL4SmmG9/0K/9nkz8/S/hmWM1H1ooDm1F1Lc2BAlLDOBnNbm4JFk1NGFHmiTI17uIzjqlRIYx2CZADZ4RVfjBkHLsJU7j/+xHmr4ghRAigSZIIYRIoAlSCCESaIIUQogEr8NygaqInNkvl4ScUFAgNVO4ccbbsA0INyV4ExfUN6iWMokWno+nPmBvtEAbAuoT0Dj60YLvzZFfuDyGReFTtHn477U/4Fo+GZV0sApQ9gmyNvP7wf0hYQsrJUUe0vB8i8KPA0puYFUM/KHdriAGwtHp+GinUNWPByYq1nHe3GYdEKN65OsdbUeL5jfACmK85r2+A4hiOEajZ0eL66n6Vi76ghRCiASaIIUQIoEmSCGESKAJUgghEryOTBqySTizPzRlexRksU02Big4RL8hKIvl7MGbmLys4+ogZr6yyAQC9iSYwCltTB7G0fFpGzo+wcVwzlzxJJfcSkA5XtwsAuVVpnFN2e4Q1A/K8okzNGAsksgHnaVKT2w7EmWJUcZWpiUF3RAnPOE9g+yajreb6PV8W6dVF0LxGvtepFkHj/AW2VlUUL0qI6MKxd5M9AUphBAJNEEKIUQCTZBCCJFAE6QQQiTIFmkwEA9iyzTKuEHxBTIXKKtlmpGVQEIRQWLRGMQWahtO40waKjPmyRFkzMymIfZD9sciISFTt4F9c6PWeaWjco7GZe/eSMGzSETJ831gMmweqExag1SgzGtqUpm+WJSBY/EV0Xb0nCKxLstvnC1GiqbPpInVELCit9HUCy0TaCNrEnCIyPrCIxuJXPQFKYQQCTRBCiFEAk2QQgiRQBOkEEIkyC93BnFOiMH6pe0geuQW0sL8gOikVcP3gvo6GvtA8AC8sgew3TDypB6h0OLPOSF/EihzFW+WG4jPyWBJ75vDuStRhlkVmYfCfRtxpgvsl1v6LVftinfDbBXypMnL3okpYJy1ILuGQAEszkKjMQsC5Ag82Yfwnkwif+7+wGfDLK+ecm0bm5uurYKsmTIjC4q8ysmfPhd9QQohRAJNkEIIkUATpBBCJNAEKYQQCfLLnWVkG5j5gDStpsdyYXCCVoDSS64kFATiqcwYnJNElBEFqV05MvLn8eckEavKcXnP1QzoUJiFc3bHOmsvGMsUUVC4gcwr+Gs8NqkvoKYVlyiDZwdtTkR5I0k5wATHUH1vLGMGGSzNTLXLZdLAbqAh2ghe4j6UKIuPuL6+5rbYBEEmVP7dbFONMhgHbpzBbmVTIo0QQpxzNEEKIUQCTZBCCJEgOwY5Al9mDkhlLICF/cawGLU18THIduTbS1VROAZJ1XygDWJDcayS4ogUbzxra4Psdd05XgTZS/B9S2ZlmpxF4FzVKS9uWGLRnPpzL2GjVtMPb7qi8djH0ybReKQF/hyXz3x4FLOOxtkYakSh7za8A03qRxxWxT74Nlo8PhjCfFDV72MF73Qb+tptes96WtzN1hJR32ByKZpUBygPfUEKIUQCTZBCCJFAE6QQQiTQBCmEEAmyRZoxLOY8lzVipgVUyKEqKHGxoJa/hHgRsRkvdh2OoCIJXGfcizyJI0FeIaOz2SQb9FbOtVLIFFbi7UhcKKGUfxNWhaOvcSSaUIn+AKX82x0vCHTaPdc2HI6i3yDkZCYM5Go58XZUGWgMYmnRgHeALB3iBuo/JFSQ2EICZKyTzXT8ovZGxz/zEsYGdM2m8G7GF9UgRQ/uRS76ghRCiASaIIUQIoEmSCGESKAJUgghEuRX84HoM1d1P7OcgB7PFe135kyXBngdVNAxslwYQsB7AtcZN+UKMrnB+XNqiEAZK26TM2/z6oaUXZPTs7P34m6ASDPT67q2TpQlU01ARBmPXJtR5RjItOjM1IWbAWyz2feWArGHuhkLDjljiLKzJtBawjXFVa/MoAIS6RnQsybYmrQacM+ie9SEykNkiUBDg2weKiogFFf3ApGGxlQu+oIUQogEmiCFECKBJkghhEigCVIIIRK8DssFEGlgu6xQPFVTRw9p6EcU8eZ++TbyrZ7SOTO8pt9IJg3FqF02AO5I3tB+sxLLhdXbWhC0bkNZ+hbU8qfy/nTP4hJZJH5NMV3CC2fT/sC1FZGIsjA/77eBfvUHfd9XEHh63XrGzRwIRWst36/V9XV/ThAIaTzGaWIZm/zgWJARA2JOo6yLKCRO9dpeWJnv+EyjLpSSi0sPNgrIBAK/a7JDGcOFQoE1i6Us8kJvcF26LPQFKYQQCTRBCiFEAk2QQgiRQBOkEEIkyBZpSNDARfEZggOWpsKaVmduI5GGfHapVFKOIENt7I1BZHrGZChbVLGpCeXCuiUE3qNg/JauFxy2zs24tkVom5/p+L6BSDCKfF42IOtkbdOLHJsjKit2ZjGtGPnjzy8suLYts/6aTq2turYQXdMc7Dc748WLVsvf/5OnQLgZ+iyfcXQbeZxBaTDYjgQw57udORZLUOZou0kksE1BiRrAcxrBuzmBMUUZeHE3SJgjz/Rc9AUphBAJNEEKIUQCTZBCCJEgOwaZGQ5xsRv61z/6IWNJ/jOXjQ8Qa5mCjy+1UYyHrvNs/a1pwTp6SEdtJcRMaFHvPNgH7JzzC6Z3b63H4nZv2+62WZyddW0diD31IBjahr9mYwcN8j3fHPk43MrGhmtb3fSLuzejxdenBv5YVK1pZmGLa+t2/b09dSqKSwY4VpdikP7eNmFR9fGVU65tM4pLkm87xe9JC6DqW9NoQfak8tcde8C/2uaPT7HWUeSVTfd/OKZF4ZAwAGOKqvI0o3enQfHGN+BXoi9IIYRIoAlSCCESaIIUQogEmiCFECJBtkiD4kLGdljWnYKt5OMLO4coIh1X9zHzQlGyzXcNccJQzkaJxgYt+I7uWQ+8vhdnvSDwtm3bXNvbd+5wbXsW6yLNVljg3IPy+C145m14Tp0CKrtEzziAaEBe6yMI7G+CdcLK5mbt99F1L+68DAu0B1C5Z3bBLwJvR8rTqVV/rNib28xspuMX4W8DYSgWTMzMymiR/+bAL6qewP0hkYbu9yRaiT4GL/qJHwZmMDa27dzl2trtehLBoe99z22zvrrsz4l2LuSZ7tssw04B/bQz0RekEEIk0AQphBAJNEEKIUQCTZBCCJEgW6ShihjkgR1vRyINxlUxK4cyXeptVGKdwOydPIveLDEHBSuswOMbe1FWwiKIKHu2Lrq2i8/b6tou2uYFgfNm6sLBfNtn4MQ+02ZmJfz92aIKQm1f4afbqrcVcN306CigTmX6N4b17JrtG5tum5mTXhA4eOSoa6sgo2drVAmogIe5CiJQWXoRiOwaJvNzrs1lVMGY7Q+9cDOF7BTKMJtEbQOonEQZOEPKeFr1mUCtVl3Mof1iX3uzRKUwsIyg7UY5rz9l6mSiL0ghhEigCVIIIRJoghRCiASaIIUQIkF+Jk2GIENtVPKLoAAs1x6rt1EguwAhIafMmFnCt9rtR42+ifrWBkuEuW5d0Ni14AP4e0B8WVr0JcrOn/dZIQud+vG7LciagWwYEraasN0MWDh02/W2Esq1NUD4YPsAED4m9Wsi+4MOiEdktv7C0cOubRhl6szN+meCJdzWfWm2Bgg3MyDcxF0jbaGEezaC4w/A0qEKcbkzsGWATB2yb+gP/Tnjdz/A+KHnS9Yn/L7C95w7Xqbymom+IIUQIoEmSCGESKAJUgghEmiCFEKIBG+s3BmmnURBUtiGVutT1gxt14hUlBIyQHKFIRKeKMjrt8vZJpE10/b93TZXF1vOjzxkzMzOX/QiwdKiF262z3vhZjYqV9WirJlckYZ8t0GkaUeZNHEpLzOzAtqIUHlRaRLV5eqCP0+r6dvoOVHGx38eebn2u5z127RL36+q58fGyor33a7Me4I327Hw5O8rZcjwa0ie1PV9UTCBrKUppDxRZlER4jYQaSBDhu2uyFuGPHriY9GcASfIRF+QQgiRQBOkEEIk0AQphBAJXsdCcU+OV3Z2vJEq90C8xXlGZ1YByjdY8LhTYGwOrAhgQfYCLGjeuaUeX9y54L2td2zxMcitcz7eOAcl/3tRLK4Flg4UD6SF7s3S7xuX2qdz0OJ9XNAPyQdVBfGuMqp8U/r9AgyOXRN/by+7YI9r64/rMcJDx30VoNDyMc4pWAVQnPwUxCWb7Xqcs9PxY4XsSmhsN2Fhfjmt71tB5SR8XzO0ADOzdhE/E9+H3MI6OZW8Xm18zZ9mlpf8kUJfkEIIkUATpBBCJNAEKYQQCTRBCiFEgmyRhipuYEQ0DppmBlspOEwqkKsgBLuh4IOBWlrwDUSNVMWoBSJNXKXHzGyx56vtxAvFzwPxZducF2nmuj6IT/YHnUikocXeDQj+l3BNtG+LBIFoO1pY3ABhhRIS0LvC4nOCaAAiX6/lj7/Y9WLLZRdGwg14SB865oWbSQUi0zSvWs2gX68ENIV3ogKVYzoFr2x6ntFzmo6hmk9m8gSNg/N3nV/7vQB+4EeOHnNtm31fAWkC10RVhdy8gdPU2as0+oIUQogEmiCFECKBJkghhEigCVIIIRJkizRGVTgyxBASR1iPyQukxpvRsd5ATBZVmjiejiINCBUzHZ9JM9f1bdsjAWZx1gs5s1Axp9P0xyJLhCL6exArscA1USZEE7KDSsjMKaMsmdyKKoFSLaAtPh4JSq0mVFOCqj+LPd82GNev8+Kd2902VJnmpRMrrm008pV72tC36bR+UbFoY2YWIPsoPwstGgcg5DQyM9/aMA4ufFtd2Nq+bZvbZtj394Ke+RQqOI0n3uZhHFlETKc+O2gKIlku+oIUQogEmiCFECKBJkghhEigCVIIIRJkizReImAv6zjGO8nNpIHjU9n1+PjTqd8TC0JlikBE3AssAwYiB93cLT2f/bJltt7WRtGDropKg0EJq3gvCPS32l6oKEkEgr6RcONEHwr+UyYTCnik8EQiEIgedLDeBOwbpv6ZbIusB9ZAMNkKWVGjBfD1BpFgAp7aVST0xQKEmdl0Atkk6CXujx+Xl6MxNQVbA3pzKhBDhsNh7Xd/E0Qm2K/ILH+IjzhqrMDFo5qe/XegviCFECKBJkghhEigCVIIIRJoghRCiATZIs3Wji+jRcpKvJK9D6vfN8F7dwSR4CmEh2OxBTQaI/EiV6Nhx4+MNBDIXGjCbgtzPrDvk0DyRKzV/rprOwaZCrGPz/yc92VZWNjq2mi7LpYj803xtYMuZGXibjtYwYs2of38SaeQcTMh7/bIe6c748vNFStrrm24uenaShKLWlByLrq3IxBpRgP/PlE2GWWUxOlH7HVPJk90fMgieqnuJX4MSputr/sxS+XarAABD4TQTqv+PJvghR5ndb0e9AUphBAJNEEKIUQCTZBCCJFAE6QQQiTIF2nmvbjQAkN3i3wuNqDU0yq0nZr64PMAos+xcFOBOIK1tSDQTNJLhh6AG5G5OoWG53o+J6mMOkdB682hv2cd8J8p5r2fzSQ6/jG4/8eOvOLaessnXRv57Mz3fNvW+bqoMT8D4lTLB9RzsqfMzCZVPM5Gbptjy6uu7fCJE67txCkvHAyj409gTLW2eM+V2YHPHjn50kuuLYBQ2Y6EoVm415sjv19FbeTnFLUVJNK4FoZEmhMnl+vHB1GF2ppQKpCyZgoQu9rN+j3rgb9QEzLCctEXpBBCJNAEKYQQCTRBCiFEguwY5M5dO31jH/x4B/VYUG8A1V8owDCEyh+wyHwUVUbhcvO0KpyiKxSDOXMUhn29KXrptyNrhka0HfWgO+tjizOwkLsPVWLW1zdqv4dTf4Y5qEzTBuuHGYg3znb8NRXRQt8QIE4GUdqyAYu7Ifa0Ma6Ps8Mrp9w23z/uY6jHTvmF3CsbPiYb38cWVGHadt55ru3CeR+XpPjl97/3Pdc2jsZtu+1jZ1TpaSOqomOW8oaP2jAGmReXpBhkVdWfCcUbyaqhBYvmW6W/TrTQiOwy2lCVimKtuegLUgghEmiCFEKIBJoghRAigSZIIYRIkC3SzG3x1V7KWQjUrteD4J0++CgPIBDfh/LvfR9QXx/Xg/2jsRclsHAPNuYFpONdsQR9ZrWgFgTZZyPhoweLqjf6PhB/eHXDtb10fMW1HXypvgh8CGX7d2zzz/diEOb2XrDk2rrnLbq2TlTOp6KgPvldQ+WVIdgHnIyqwhw75SvrLPf94vETm/4+vrLs912JhK2y6Z/bAiwwb4PgULa8wLN1+w7Xtr5RP+fG0PefFlWTdUWOlzj6o4PlAm1H1XZ8tSDoFvSL7BssgO0I+LQXsagHWmllcPxM9AUphBAJNEEKIUQCTZBCCJFAE6QQQiTIFmmOLi+7trmOX7U+065HZrulr15TtP28PCp90HdIHr1Rpo4FH8geQzYJeyt7Aq66z5BpqOI/ZDPEFVvMzLZG2Rc9yAY4ccoLMt996bBrG7S8wPPySiR2QRWdAQg+43DUtQUIeDchMn7h9nqWD/mjkyDT7vr7s7LmxZDDUeWYtZHvwyD441dtL5gcWfmua3vplfq9LUAc6R7xAuSw7+/jLFSYWdzis6BmZ+ttoYAKTiAydeF5kl1DJ6pq0wThCf3LoQ0Ftlik8Uc3SK6xAFlo47F/r6vgx94kus4WXBN7yuehL0ghhEigCVIIIRJoghRCiASaIIUQIkG2SHP4hPe4peDz9pm6KEN+2s02lEGa+K50Jz4IPo6C/RNYhU8e2OSxTdkvOVIOJRGQvUITtmuDMLHYrZcym+t4YavX8uXOhpW/Z4fAq/m8rfUsmVbPH+ttS7tc29KC94JuDbwIMez7UnWjYf0ahmAZ0Sr9+IEkH1tZ8SLNJLL76M36MmPzTS9UzG734/EVKIu2FmXqbN++zW2zbXHRtf3Xf/w/11bCgCzhOlvRKDpvqz9no/TvxMKi3+7kyopri20qSByZGpROg3JzUxI9XaYOptL4Y0Gm1HAMIhC868PIbqIE3/MmCKO56AtSCCESaIIUQogEmiCFECKBJkghhEiQHb08teGD89XEr3afj8o9hRnIpAHfkbINHhQjaJtkBGULCPBCUHmKGQIQUI+CzTMdHyjfOuuvcwZKX3lZwj+EWfDt2Ap+11u3+XJk551YcW3bIgEjgBS1CB7PWzognM2AN8sMXNU48g6CoPsASrhNwS8ngHLTKSIvklmfmbJ1u79nJ6FE2f++9DLXdsnu8+t9ACGhmvrxv+vKd7m2ggRCEBxOrNZ9dSp4Tnt2ne/aplCObAG8cTai8oHLJ71HeAFe3OOpHwdDyNQZRRls6IsDWVeYqeNaEgJq1AjJd9YAb6tc9AUphBAJNEEKIUQCTZBCCJEgOwbZgOodTaiSEfvetmGheOwDbWZWQpyggPhiXMedZvg4ZvjqsaANFsBOwBqgjLZbOs8vzH3Hki+h3z9+xLWFsb/OSVRav+r4bZptH7Na7Pq45xV7vCXCJbt3Ry1kNQHPBNqa5G899NYY/fUonlZBDHgElYEgftxsQCw0eiYdGJ+LELfdCVV01hZ92+ZGfcF9NfIL3cm3fTr1cdXNTR/3XIYKRdNxfd9XYIF80abEizx7gl6vPl5WIKi3ddHHLvt9f+226ZMDptHCc7bZ8Iei4GKD3myItcbxdDp+gH7koi9IIYRIoAlSCCESaIIUQogEmiCFECJBtkjThEDqXA8WR3frC4kLqF5Di0ULEHxasGC6VdYD47RfA2wBCqj1XkLfGuYD77GWM9P2/brkogtd28FT3qZiAF7fw2E9OD8awgLqJt0LWEgPgezZaDuyOW5ApBwr1Vf+ng1Gft9xdLwpiDSNAM8OOkc2FQ2LSu3Dou3WwIscnZ63pJjt+Xs7atS3G3tNwiZDf02jIYw9v6ttBj/OupGtwxREoJWVVde2dadPGJjCIu0Tyyu130MQDMmeoEHvThOuahwLJqSYnNlPOwkJPFEbnRP7kYm+IIUQIoEmSCGESKAJUgghEmiCFEKIBNkizfZ5n20wA1kykyiwvAmL8CE278rBm7GI0mrVu0wiDS7Wh8b4WGZmBa3Wn9YFASpVv+M8n0mzvsMHz9fXvUgzGNRFmUnPZ6sYVE9pQlu7gMB7dO2UodQgFQ6C51Bsx6aQtdEs6vd23IB+wX5UdQlD+FF1nQIyfBoTL3aVExhT8Mw70diopn6sjyZ+UK2bF4u6cE3lFKwHIi/oKVT82Rj5qlptyGqhZxeLgVTVqT/y94wyUSg3JRZCyXKBxCN6Yel9JYEnvgZ6N4NEGiGEOPdoghRCiASaIIUQIoEmSCGESJAt0izOeY/kACWmBsN6wHhageAAwsoYjkWh1ViUaUAgmPYjX+wOiBWtNng1R8HzwcgH4mOhxcxs9+49ru3Id77j2jYGdSVrDBkU1dTfxwLa2hDdbkdZDwWIUwFEmgrubQOC4DaAjJLoHqHgBh7PRIO8lCPhYDj092w08m29WcjUafuMsDIWMCCTaQgiRzWGcmeF39cd38xCZFlA7xc02Qp4YDealH0Un5PK/YHYRVlWUD6w4zLM/PFjH2szFlEKOidYtcS3Awubnb1Goy9IIYRIoQlSCCESaIIUQogEmiCFECJBvi82eGiUEKhtx4FaKFVVVeDLAsF/8peIM13c+cysHHgRhTywC/Ct7nZ8wD7WIDahHNm3/+uga/s/l77TtXVmvNi1EXnS9KEM1XgK/icggFUU2C/j35DhAJHsEWTqbGz6TCAqwTWMrqnX9X7aXGINPNNLL5w1m/X+TsG3ehXGrEH2ji34fsy06pkzzSZ4nIM/eqfj+8oZW9CP2F9l7K8pQNbPdAwe1TBGY80Nvb7hPWmA8EfPqdOu940864vCv5sjEG6o7B0JffFon4AxdoVpOXnoC1IIIRJoghRCiASaIIUQIkF2DHIVqtBQ6f443tKFxbolxHPQGxdKvcdxqy4s7B51fUxjQP2AGEkJccliXN+OFiX/+0Efg9wy48v7z8/6GOSpfj1WtjnxcZohxBuprQRf5umoiBvcNmOoHEMxSIoXjSFmGi/gb4J9RhfuTwsqRIUChmkU294AK4sBeFmXkd/1qyeAWN9s3VO7BwvFA8S7aMG9wTijRfhxGH4w9s9pjcZx199HWjAdj/cG2Stg5Zu8uGQZPZMC4r1ULatZ0JiCZwJVheJeUP/5mvLQF6QQQiTQBCmEEAk0QQohRAJNkEIIkSBbpBnAYlTeLqqyMvHBVlpMS4tuWzB/x8H/Fgg+M+DXTTYDtPiXAtJxxfwhiBcvnzzp2v75W99ybf9n72WurRUtql6DRb6bELDvgdhiY7IUiBposTGVqoftyMI4x/ZiDFVisIITLF4egRg1iKrmDEGQKWKvCTNrFP6cE7BmWFuvn3MMIlMJN6MPx9oAGwN6L4aRWNSHcbay4Re/V31vudDu+negG71jLaj4Q+OfrB8IJ3qCNlLB/af3MMCC9RH0I8Rjgxa6v4FyPvqCFEKIBJoghRAigSZIIYRIoAlSCCESZIs0FZWIpxXqUbA/+IX/1ih8sJWsDgwqnrhzQlC2BNFgpuezDTAVCE2169c+BkGDStUfXvbCzaGjh13bzm792teGXnAgkWYGMm4a4Ps8dZdJIg0aXPjjwzigLJnYr3gCY2Vt03s8l3CdA7gf43G9reWUKLMmZEWRZ8EEqkvFFafi85mZFeB3PRj47db6/joHIEaNo1s0gr4OJ2BzAmJdB44frC7ctMjPPFe4JI/q6L0g8Y4EE2qjd7iAeWNaxV7ceeM4F31BCiFEAk2QQgiRQBOkEEIk0AQphBAJskWaXOIQKcX+KWBP25EFcxwcnkDQmo7V6ZEI5IPsQygnNY0yGtDWwB8dbQwGUBpso6hvR5kXFZXMAuuECRS6mkQe1ZMp+SGTNzEE8aHsPbXFFgvttrdcoJJcsZ+2mVkbxJBWq/48Kyg9NoUyZmN4viMYaM3IS7xDXuLkKw2Cz9hAMAExZBxbLsD9J8uICjJuaBy3omtqQrYNWZh0oQQdPSeL3k0SaZpkwQJ2IqGgLCiqieibzmKTJPqCFEKIBJoghRAigSZIIYRIoAlSCCESZIs05F8RB2Vf3fAMvxP7jcFvoqp8IDhEAsmYPIGplBSII70ZLxxMYLthVH6sgrJLFHzudr0wRIHmcVSyaRVKWk1hvyaUjetAxlDsobMMPtbHjq64tmrsnwn5W2/ZMu/a5nt1T5e5WfIg98cqYUgGyBiKM1bI+3gM42xz6EuDjUa+bXFr/Zq2bfXX2IJMnUYLhAnwEm+MoKxbLEDC61WWXkRpGPjAwzsQvyuh7Z9vWeSJNOQF1Y98geLShGZmJYxZeieG4H1UgpjWmEb7kvIHIl8u+oIUQogEmiCFECKBJkghhEigCVIIIRK8IZEmJ/RJAdgGZF5MyLge2qoqzqTxwVzKdGm2faC50/GZBCQWxaWXSJDpgKfO3IwXTGKRycysiv6eWt30osEGZEZUlNVC2RG9LbXfw7Hv/8pJX6brxPKya1vcvuTaLr78f/lzzkYCDGQCteiZQIbJ5sYp1zYTlR8bT/z9ObW84tqOf+dF19aAZ74wXxeZ5ufhWcILEDZ8aTPy+6Fxtr5Rf+4jeOYlZNKUmJ3i353JuN42ASGnAGGlTb5PMLY7UXYTlamLy+CZsZgzBYGtMaa5xJ0AkCeNEEKcczRBCiFEAk2QQgiRIDsGSSX5KS5ZRDGSgkq4Q1ySYg4TOGfs0RvHJH/Qs6ymCcSBKAYTx3jKwsc9aeHsTM8vhO5CjDC+HUOo/nJ83S8e3w1xphlom+3V46PzC1vcNnv2+Ps40/J9XYe45LGXvY3Exf/rZ2u/53bucNu04jilJbyaTxxzTf1T9bjkqVdedtssn/B9nYIlwu4di65trlePjzYgdjyCuOcGLArvQ+WbNYgzn1xZqe8H/ugG96eE96mCthCN99HQ92syofHpj9WDBd+9aEH5yWWoZgXnJC90iqEGWgXeiCsIkTWM3y0XfUEKIUQCTZBCCJFAE6QQQiTQBCmEEAnyRRpQOUrylY6FG9iGCm7QWk4ShmJdpYIILC3MDRs+KF5A31pQWj8uv09B8V7XL3recd521zYB3+dJVHK+avpF569EAXwzsyUQbnqwgLdoRsIE6GadGX9N27fPurbFpr9n4bAXaU5ED2qyZ4/bZnbbNtc2rbwAtnr0qN8u8tSerHhBpnXKLzDfChWW5ma9MBEPDVr0vNb3ggx5fQ9gQfbxFd+341GVpQFU/CGxiL5ymrCgPFYrKhBHhn1Y3L3Fj4NAFa0iAakL9g1ULSsWWn5wAr8ZzBzN6F0kQYkWp+eiL0ghhEigCVIIIRJoghRCiASaIIUQIkG2SBNA0AiQSRPbK48hKEsh0zb6DsM5o+AtZcPE2TZmZgGEm/6AKqOADUAUCKb498yMD/SXUMFmPPQiRD8SAMqGF3xOnlpzbYcgg2XL7Jxri8WoNlQBKppQxaUD9gELcH8g7l4O6wLG+KXvu236kJWDZfpBjBpFthRh6MWRDgT/W1CVpzkDvs+RoNFf84LMOmXNgE3FGjzzg/DsVjbqmTNDEkZBlGyDzQNaSEf3toDjk4g4gKwfm/fjLBaQelDhqii84EMizRiyj0KAFy/KYCNhdzxBWTgLfUEKIUQCTZBCCJFAE6QQQiTQBCmEEAmyRZoKVrEHMO6t4pQYCJo2wU+4BeXCqEzRKAreUtl4slyg1fTolR18wD7OrgmV7+sCBK0pPaiCDIFYzKF+gYZi3z18xLVtmQP/5gvqwfI5yNRpQ6C8JJEGMmma8PdsGaI2yNroj73wFCgzCsrLWZT504IycqD7WXvOi0wFlBBb69eFifUNL8hsQOmulU3/7P7vd7xA9eIrvoTbIFI4/R0zq8wfnzLC4gwTM59A1YD9GvSeQHbNANo6C/Wx14Dx34GHMg/ZXxPwQm8OzpwlM4lVYjNrl7JcEEKIc44mSCGESKAJUgghEmiCFEKIBPkiDQTZqaxYFWW2kC92EwK15O3baIAXdNQPCupTG1nXTKbgqQ3XOTNXDyL3Or6vvZ4XCaiwG4lR7VZdNBmDF8kIgs/rUA7r31885M9Z1Pt78dJOvw1kPTQhQ6P0m1mj4UW3RqO+YbPw191o+Ps4BYGNSqBZ3Ab7YQ09EJn6JLas1suRrYGXzbFVn+Hzbwe/59qe+y//TNbH/pripxlApqGMsCmIpQVkcTm/FhhTzTZ8M8H7tLnuM5fmo/eESo9N4f1qgWg7C35OKOBF19CBMduAzLFc9AUphBAJNEEKIUQCTZBCCJEgOwZJ1XZGEEeJF2lTnHII5es3Nv3xKYYRx1YaEJ6i0BOuOqd418QfsIyqFrXbFB+BEvQQB+qAn3DcN4rbjiAGNoBKRq8cP+na3AJhiOm1du9ybV3wrcZKQODh0GzWY7LtNlU78vfCJRqY2RQWDU+nURuMM4oxb0J8dzmKN5qZLZ+qxxeX13zMjSryHDrs7SH6EOurKC4WxdwbOGYpvg5aQIBF1VW9bQox8jim94OeuBayoNjcqN+juXlfuYcqA8Gjw3cA56BQf8ZkOdJu++SPXPQFKYQQCTRBCiFEAk2QQgiRQBOkEEIkyBZpuuD7XJD3QBQDH0FlGvSyhkBzu+PP2a3qwX4SVUgwYQtvHwgGXcgajXrfCgiwY4l4WADbbJLIEZXCh0XVtHgc4vAW4JkcizyYXzjkFzO3IRDf2X2+a+vOQrWglu9v3NaFajtN2I8kgunED9PJuN42mfhxNvE6gq33V13bKix6Xl+vV+85teL3a8O97sF1drqQMFD5zo0jUQmGMVbboZtG6+arIqoWBNuMwHKBLB2oH6fW6tWZ5reALYM/pQ1AgCTPiNh3+9V96/0dQ/9LLRQXQohzjyZIIYRIoAlSCCESaIIUQogE2SINlWfvwAr1SbQsfgyWCCQuUIZAgEhzp1sP7E8mEOjv+3OSTzCVpacy8bHPdgHiEQk+VJY+rnhi5rMGCvAbb0O1Hav8OSsIZMfPjjJwDh874c8Jz6Tc7c+5fXGr3y66pgD3h+rv0LW3YJzFPRvBONsE4Wxt0wsygyFkd0Siz7Y5nxXSm/Ftx/peTDsBVZfWoW/NSCGsQDEMMD4p4YaEUJexAu/EEO5jEzLmDCo4bfTrwtZg4O/FwpYF10Ze1hPwsiZrjEGzfg4SS0nIzUVfkEIIkUATpBBCJNAEKYQQCTRBCiFEgmyRZoJl3WG1e1STvyggaArltjDThcqdRdvNzPjMhTD1WRUN8H1uUVYL9MPbMJAtgA9uU3bHGALGcfZFLHCYmc30vLhDPhLrkBXSiMquBcgsoAycPvT/O6+85M/Z957Ru3bUy6dNQDRogj93Cf1owDiI/dHXNrz9wal1X8ZsPPbCQQvu97aoVFer6cXAVRIhZnyJuLLyAlgTxJZ2ZAcxQfuJPOEGy6K5/QAYU0MYs6DRWBjX9z0J2UcLIOjNzfqMm9VT/tmhgBeNl7g0oZlxelwm+oIUQogEmiCFECKBJkghhEigCVIIIRJkizRUPomyI+Ll+eQtEcj3Ag5VgodxHHwmj5fpBDIvyIcFPGPIRyauO0XiC/kVTyC4PYTAfjvKEKCMgRZlyPieYv+nzpsFsoXg/nTB63vXdh9kD5D1cPx43ZtlY92LKFQCrQThhoj9ZkYjf1+ryj+nDj1zGEOtyKe9AN/2ETzzWfJ4hnN2C3gHItFwSGbuAGWioDd89Bt0SxRuKEspFv7onMdBpGm9/Ipr67ShnN3Un3M69Zlp8TvQ7ZL/+tl/B+oLUgghEmiCFEKIBJoghRAiQXYMcgRxtwIWR8cLpiuoHIORS7JhgDhEvOC73fTxxh4sHp8MqRQ7VKvBuGp9O4othoKCtBCXBAuKUdQ3ig1NoVudlo/Xdds+BtOP4n/9vq9e05j3C9Gn8MybsBB361ZfoSVEz4780dsUD4QYHtGMkhQaATzaxxTYBvuABllG1O8thQO70NcdW7a4tncsec9xiuudiLy3A8X5KN7Y8PeWo5f11greRBp7Y9AMSno3o7FRjfwzObHq45LbF/34aUEsugIPipadeaE4xWhz0RekEEIk0AQphBAJNEEKIUQCTZBCCJHgdVTz8SIHVVmpImGiguA87ccLT/2+8fGpakkXSvSPydIBRCaq1BNfA+0XB6hTbRREjhfYojhFlV1Ag5gB//LxZr3aDi2qjj2NzcwCiC++br8Z2CZbM3oGtHCZ/n6mYiwYYo/uB63vb0G1qUbLD/kSxIq4SswYnnkPhITFGS92XXDeea6NhIPmy4drv4+u+GdCVaPIugKKb1mIvE7okeRW+JlAWxk3gXi0DgJhCxaKz/V8VaQOJEvECRp9SMSgOSgXfUEKIUQCTZBCCJFAE6QQQiTQBCmEEAnyq/lQRJdKmUdtZJtAoeC4oo2ZWRuCt8NBPcg7GXvxqA1VaNqQYTIBsYKEoUmU9VBCdRBa+U9ZORQwdqIM3OsW2CQMwXe7Pee3a0fCRAkB9rU1X21nGaqxNHbvdm1NyOjptOttJMyhSEBVaKCtiP5ub7Th/gfwbQdLB8rdcb2FrJwuCD7zJJLRq1PsdG0z0RjtvuQr33wX/MtXB/4dILFlGos0ea8mPxPIkKviA8IJRq6ylNkGjONYJDMza0LbOPLsnkJlKcriykVfkEIIkUATpBBCJNAEKYQQCTRBCiFEgmyRpsAyUT4IO41KI2HWDNrUQmYBnDMOspPoUUEpKbIssKbfbjzybbHvMAV9vXe2WbP0whCVqxoO62JRgAB4LHqYmRVQ/ilAELwZiUptCHZTqfojR4+5tpO7l1zbzm2Lrq2MBAwKutNAoPtTQWZRVcXjwD/fKfie07HILmMalaUjoYLKzc12QOSDfem96ET3qA0iH7WRcLMCws0gGscw1I1yy0i4qeA5TeNxC8JiA7KWYhHUzGww8v2njJ5ptG8s2piZjaAtF31BCiFEAk2QQgiRQBOkEEIk0AQphBAJskUaKsFFxMHnEoSWkoLz4PNilRcOnCcKZqb4Y5H3bhf8kKmUWRUfD4LukzEIQ67+EzMY1DMJ4sDzD3rhWqj802ZU2szMiwkBgufb5+ddG/mTHDz0XddGIk0vyiiJs3nMuPQbGRZVmIUTdw4C+CCixF45ZmZTGHvj6JxUnqwNXi0zkLQBmhuKFbFnd6/0ZdK2dHymzvbZOdd26NhJ13YkypZa6XshpA/jn0YxJJxZfGsbIChRZt0EbhBlWY3pvYg2JPuZCTynXPQFKYQQCTRBCiFEAk2QQgiRQBOkEEIkyBZpFhd8EH95ecVvGGVtlJDN0AFxpAVBfAqoN+LoLQT10TMGor4lZZR0fKm0uMQaBdipTNo4ysYw4wyKOPg8giyCCkLlE8iuaVKJteh4FZRr2xj4klO7Fra4tuPLx13b91552bUtzNW9WVoUsIcSdAUISCW0uSwcuK9NiM1TFlSjAfc7ivaXJXjxwNvTAaOgcSuvBFd8uG7PH2u29Cdd7Hr/lp0L3k/o0PHl2u+DkIHzyqlTrq0PAmQDSpmFaX1cBfAECpUfe1NQA4cj/+4YzCXx2KAMnzgT7vWgL0ghhEigCVIIIRJoghRCiATZMcilnTtc2wBKpW9GbWMogd5t+1hCD+Io5HUcL6qmFaUUc6Cy/ROKcUKsrNmqx8qqqY+PUOyDjk/E8agpxDM3wO+XqpSQDUAvtlyA2NDJlRXXtm1+1rXNLy66tsPHjrq2C3bVLQVaVNVp1h+/0/ILodFzvFGecZsA56SFyhT3jNtom0YBz5dLVTnI5qGIroEsEXzU2azVAA9piFXOz9QXlC8uLLpt/v1lH0/+LlR1orhk/AZUsEC7KqASFlznCOL3lCwRe7KPK/9OUCWyXPQFKYQQCTRBCiFEAk2QQgiRQBOkEEIkyBZpqHxHGxYqDyL7AFrIHQejzczaUHkFg7JRBZvJBBZjw5EIqlBEJfnjqjMN+HuFLBcajbwqJbFIE+D4E6hQ5ErcJ/oRL7gvYKF+CQuXjxzzwfm3L3k/5/HEL7ReXVur/Z6FReFkWUCLwstAAkn9N/uv09//efYHRSTWxb/NePyMRl64nMD9wUJGUeJCAdcdwH+9DQvRW6XfrhU9g07PizutnhfJChD+XoJF5uuRR/0YxmwAeYqeeUDTbnjvXDUfeL7w7HLRF6QQQiTQBCmEEAk0QQohRAJNkEIIkaARyPBXCCGEviCFECKFJkghhEigCVIIIRJoghRCiASaIIUQIoEmSCGESKAJUgghEmiCFEKIBJoghRAiwf8HVp7Gy1VXf38AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Reward\n",
        "Finetuned model attains higher reward than trained DDPM model."
      ],
      "metadata": {
        "id": "IINJD4XqkboV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddpm_old = DDPMModel().to(device)\n",
        "ckpt_path = '/content/drive/MyDrive/cv프로젝트/부트캠프/_100.pth'\n",
        "checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "state_dict = checkpoint[\"model_state_dict\"] if \"model_state_dict\" in checkpoint else checkpoint\n",
        "ddpm_old.load_state_dict(state_dict)\n",
        "\n",
        "ddpm_old.eval()\n",
        "ddpm_cur.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x0_old,_ = sample_ddim(\n",
        "        model=ddpm_old,\n",
        "        shape=(64,3,64,64),\n",
        "        alphas_cumprod=alpha_bars,\n",
        "        device=device,\n",
        "        ddim_steps=ddim_steps,\n",
        "        eta=eta\n",
        "    )\n",
        "    x0_cur,_ = sample_ddim(\n",
        "        model=ddpm_cur,\n",
        "        shape=(64,3,64,64),\n",
        "        alphas_cumprod=alpha_bars,\n",
        "        device=device,\n",
        "        ddim_steps=ddim_steps,\n",
        "        eta=eta\n",
        "    )\n",
        "    reward_old = rm(x0_old).mean().item()\n",
        "    reward_cur = rm(x0_cur).mean().item()\n",
        "    print(f\"Reward Old: {reward_old:.4f}\")\n",
        "    print(f\"Reward Cur: {reward_cur:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUfUq0vfkdqo",
        "outputId": "440ca618-c4eb-45eb-c7a6-4e318bdbf73d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward Old: 0.4847\n",
            "Reward Cur: 0.6686\n"
          ]
        }
      ]
    }
  ]
}
